{"cells":[{"cell_type":"markdown","metadata":{"id":"fLdDdiCWTuW-"},"source":["## 1. ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23598,"status":"ok","timestamp":1722177200464,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"mQKDlSmxVVr3","outputId":"fb710d23-7f47-48bd-e93a-4490e0fa6a71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"3dT4v3a_aZMi"},"source":["## 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ install & import"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59048,"status":"ok","timestamp":1722177259503,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"nsKTJfE8VgNK","outputId":"1f8fd5bd-fe73-4f32-e197-65a997adbe10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.5.15)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.4)\n","Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sacremoses\n","Successfully installed sacremoses-0.1.1\n"]}],"source":["!pip install accelerate>=0.20.1\n","!pip install torch\n","!pip install transformers\n","# !pip install evaluate\n","!pip install nltk\n","!pip install sentencepiece\n","!pip install sacremoses"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9361,"status":"ok","timestamp":1722177268851,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"VcgWlnZLA4Ex"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import (\n","    MarianTokenizer,\n","    MarianMTModel,\n","    MarianConfig,\n","    Trainer,\n","    TrainingArguments,\n",")\n","# import evaluate\n","\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","import pandas as pd\n","import random"]},{"cell_type":"markdown","metadata":{"id":"a5rwJChqHobs"},"source":["## 3. ë°ì´í„° ë¡œë“œ(train:validation = 9:1)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1815,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"K4uY9GJLVhG4"},"outputs":[],"source":["# ë°ì´í„° ê²½ë¡œ\n","data_path = '/content/drive/MyDrive/'\n","\n","# train / validation ë°ì´í„°íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n","train_df = pd.read_excel(data_path+'sum_tran_train.xlsx')\n","valid_df = pd.read_excel(data_path+'sum_tran_valid.xlsx')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"lDFob6h2Vt4R","outputId":"b536725d-a04c-4fa2-a7ba-98fa441ef92e"},"outputs":[{"data":{"text/plain":["((350, 2), (35, 2))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] ë°ì´í„° í™•ì¸\n","train_df.shape, valid_df.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"A1H1IR5ZWgpe","outputId":"1d99998e-eda6-4ca3-ace1-6a280c2879a8"},"outputs":[{"data":{"text/plain":["(                                                  ì›ë¬¸  \\\n"," 0  ì½”ë¡œë‚˜19 í”¼í•´ë¡œ ì†Œë“ì´ ê°ì†Œí•´ ìƒê³„ë¹„ë¥¼ ë¹¼ê³  ë‚˜ë©´ ë¹šì„ ê°šê¸° ì–´ë ¤ìš´ ì±„ë¬´ìë¥¼ ìœ„í•´...   \n"," 1  ì¹´ì¹´ì˜¤í˜ì´ ì´ ë¶€ì‚¬ì¥ì€ ê¸°ìê°„ë‹´íšŒë¥¼ ì—´ê³  í–¥í›„ ì‚¬ì—… ëª©í‘œê°€ ì¢…ì´ ì—†ëŠ” ì‚¬íšŒë¼ê³  ë°í˜”...   \n"," 2  ìƒ¤ì˜¤ë¯¸ê°€ ìœ ëŸ½ê³¼ ì¤‘ë‚¨ë¯¸ ë“±ì—ì„œ í™”í›¼ì´ì˜ ì œì¬ë¥¼ í‹ˆíƒ€ ì¤‘êµ­ ì•ˆë°©ê³¼ ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œ ì˜...   \n"," 3  ë¸”ë™ë¡Â·ë±…ê°€ë“œ ë“±ì˜ ì´ˆì¬ë²Œ ê¸°ê´€íˆ¬ììë“¤ì€ ë„ë•ì  ê¸°ì¤€ì´ ì•„ë‹Œ ì£¼ì‹íšŒì‚¬ì œë„ ì›ì¹™ì˜ ê¸°...   \n"," 4  ë„¤ì´ë²„ê°€ ë§¤ë‹¬ êµ¬ë…ë£Œë¥¼ ë‚´ë©´ ë„¤ì´ë²„ì˜ ì£¼ìš” ì„œë¹„ìŠ¤ë¥¼ ì“¸ ìˆ˜ ìˆëŠ” êµ¬ë… ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•œë‹¤.   \n"," \n","                                                  ë²ˆì—­ë¬¸  \n"," 0  The suspension of repayment of the principal o...  \n"," 1  Vice President Lee of Kakao Pay held a press c...  \n"," 2  Counterpoint Research analyzed that Xiaomi is ...  \n"," 3  Super chaebol institutional investors such as ...  \n"," 4  Naver will launch a subscription service that ...  ,\n","                                                   ì›ë¬¸  \\\n"," 0  ì •ë¶€ê°€ ë‚™íƒœ ê´€ë ¨ í˜•ë²•Â·ëª¨ìë³´ê±´ë²• ê°œì •ì•ˆì„ ì…ë²• ì˜ˆê³ í•˜ë©° ì„ì‹  ì´ˆê¸°ì¸ 14ì£¼ê¹Œì§€ ë³¸...   \n"," 1  ì¼ë³¸ ì •ë¶€ëŠ” í•´ì–‘ ë°©ì¶œì€ ì „ ì„¸ê³„ì—ì„œ ì¼ìƒì ìœ¼ë¡œ ì‹¤ì‹œë˜ê³  ìˆë‹¤ëŠ” IAEAì˜ í•´ì„ì„ ...   \n"," 2    SUVì˜ ì¸ê¸°ê°€ ë†’ì•„ì§€ë©° êµ­ë¯¼ì°¨ë¡œ ë¶ˆë¦¬ë˜ í˜„ëŒ€ìë™ì°¨ ì˜ë‚˜íƒ€ì˜ ì¸ê¸°ê°€ ì˜ˆì „ ê°™ì§€ ì•Šë‹¤.   \n"," 3  ì‹¤ì œ 90ë„ŒëŒ€ ê¸€ë¡œë²Œí™” ì‹œê¸° ëª¨ ê¸°ì—…ì˜ ì‚¬ë‚´ í† ìµë°˜ ê°•ì‚¬ë¡œ ì¼í–ˆë˜ í™ ì‘ê°€ ìì‹ ì˜ ...   \n"," 4  ë‰´ì§ˆëœë“œì™€ ë‚˜ì´ì§€ë¦¬ì•„ ëŒ€ì‚¬ê´€ ì„±ì¶”í–‰ ì‚¬ê±´ì— ëŒ€í•´ ê°• ì¥ê´€ì€ ë¦¬ë”ì‹­ì˜ í•œê³„ë¥¼ ëŠë¼ëŠ” ...   \n"," \n","                                                  ë²ˆì—­ë¬¸  \n"," 0  The main point is that the government has anno...  \n"," 1  The Japanese government drew the IAEA's interp...  \n"," 2  With the growing popularity of SUVs, Hyundai M...  \n"," 3  In fact, Hong, who worked as an in-house TOEIC...  \n"," 4  Regarding the sexual harassment of embassies i...  )"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] ë°ì´í„° í™•ì¸\n","train_df.head(), valid_df.head()"]},{"cell_type":"markdown","metadata":{"id":"dBNWzu5RHuJ1"},"source":["## 4. ì‚¬ìš©í•  Model, Tokenizer ì •ì˜"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351,"referenced_widgets":["7771afadf5c548bcacf3b7cdf04b2965","01f9b1bbab5940e89f4ede691f449186","ab9f7fdcbdaa4e19b015afcb404e65ee","f378be1fd1e94f7383802db7542f651d","da15cd42ccdc445ab7bd616f5b485bbd","d48cb922e710416aaa9cb98320114660","842391b85c1344bb9d5c01f87db6af90","d7db8133f5aa4afab4ac2e1926707f19","a6db92ad600c4ab6b5e22ac2b9d63aca","b2b4aa9fac06489bb1cdc4e8a272d260","d8e453789e0848e3a684ed9dc4b73f5d","2f4afbbce8f1493d9bad76ec095547e6","4e8f5a03dec64cf0b7b1f740fb4348be","b43cc672daf14d888c88b77bea3f8491","8f75a9e777f34f639968891bc6b29782","6e04e4df1f8346b993ef3ea0fd5ba650","9bc08c6ebfa944e2aa53b82dc3068292","d4cddfedced5416f81e4cf4c57136035","ce5de4c3598448228f90e2cc60c68302","12e0b17dd4eb47019ba73f8c822f2d72","962b13e90d164805ad4d2fda6f8518d7","b0d69b5925b248838591a13850419f00","6591aed40e7543b0820b0a6e7c8d2a2c","181193808d154ab6ab06139a1431a45d","0200f3ffdb144b46ab22031e180d42c3","727ba9717fc249648919f0f4a0f45260","3637fb87d5034918b35635ba21b94b72","369b7f4ccb9645a5916ad175eeecca45","a8da0773f20543fe9db10b77a13b3cf7","827721f0786e4a4eaeab5ab1350452c5","e5fd3bce32644150b5edddfac644c4ca","5110cd60952b40788becef79b0c96717","d3d195e65ac3439aae7fb9b060b9f129","75604c9279ab4628bedbe0b10aa9c1be","d1162b31f6c34cd1b7f139a4a462a45f","f9139877639445b28a900f9e1de7eb29","c45dac4045fc47b2a5d385b403551c85","0563b2f5e5ee4d47bce6219d7403a22b","ce6dfc1b1e484ff286dad5b5648ee7b5","f85b18fef9c842c583c2c11688b4fed0","bc09af2b929340999a32301295a78348","e4fd9a73d3fb4621ac01bd640da8d9a4","1a969522b87942689a54999b73282fea","139be2cc5a4c41f6b59cad4b28396cb0","0efdac02a822460daf5f1fc79da062ec","6011c3f1a2fc4193b25cf1402f1da524","26180c7a68f3446b9cc2c0f5959b0cbe","3ccda280f6564891a3168bed90d66965","ad8fcdb8b5b342bab2841a5ed577987b","514a9ed5e4834fe09f3019e98e970b09","de3015d0242c43dba3f491b06510bebc","bb8d0dffdfec4ed2bbe97c59708418b7","58c3d62b797647af9ee1a353a18ffe7e","3793225c8851405ba0c5e316562edf7b","4afeb784e45c489383c420242e6c6b81","5af2c3aa4b564bdfb9fcdd6d554ec233","dc18f7dba0b749b6bc3c34724aa70a8c","24677bc16fb749a0ab04dd1c8cb1c0eb","e29b3eac44c745a195b9f7bea16e9944","7dce201b10dd48ca94e992447150d535","5b4dc50063b04d5a93227125982b2e94","d59047c3687b4812b7891a9668cbed17","0b8846a7d62c4bfdaa586a9b3dd8f38e","5d756e78768d420ea1390d0b56ea14db","d6253f9cfe68460cbcfec407997254e0","f1a8f61b88d94d748dd39adb0cd060e3","6343603066794320b2fbb17a1d19c64d","b26edd9dd91f405391f9989f4383b451","c28b94deafe34d1389a10fe0dfeedd54","cb1e0f6451e944029b250ec415e75a7b","45fcbdb03e2d41af8f71ddb313375d4b","4e594b68d5464ddd918f753bafe1ed96","72e6f83dd4df475082135ba9befc977c","f15dffeb454c4dc9a766cb05aa074bd6","893af6876a6544ed8710d2f578c4cd17","ede84c66848545378235d83b7d9e8faf","de72e131915544e9a728edaaa1ac68ef"]},"executionInfo":{"elapsed":13455,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"WSQ6VN52VjRR","outputId":"66992f98-dbf9-4392-dd23-0a8d9855c626"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7771afadf5c548bcacf3b7cdf04b2965","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f4afbbce8f1493d9bad76ec095547e6","version_major":2,"version_minor":0},"text/plain":["source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6591aed40e7543b0820b0a6e7c8d2a2c","version_major":2,"version_minor":0},"text/plain":["target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75604c9279ab4628bedbe0b10aa9c1be","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0efdac02a822460daf5f1fc79da062ec","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5af2c3aa4b564bdfb9fcdd6d554ec233","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6343603066794320b2fbb17a1d19c64d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# ëª¨ë¸ëª…\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","\n","# í† í¬ë‚˜ì´ì € ì •ì˜\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# ëª¨ë¸ ì •ì˜\n","model = MarianMTModel.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"ZJ_92GVzjrHh","outputId":"768ff4ae-0681-46b2-dcba-b4c62f809e90"},"outputs":[{"name":"stdout","output_type":"stream","text":["MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-ko-en', vocab_size=65001, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t65000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","} MarianMTModel(\n","  (model): MarianModel(\n","    (shared): Embedding(65001, 512, padding_idx=65000)\n","    (encoder): MarianEncoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianEncoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): SiLU()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): MarianDecoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianDecoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (activation_fn): SiLU()\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",")\n"]}],"source":["# [Test] tokenizer, model\n","print(tokenizer, model)"]},{"cell_type":"markdown","metadata":{"id":"Z6mM0ZstH_R6"},"source":["## 5. ì‚¬ìš©ì ì •ì˜ Dataset ì •ì˜"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"4iSfJP9w7jYg"},"outputs":[],"source":["class CustomDataset(Dataset):\n","\n","    \"\"\" ë°ì´í„°ë¥¼ í† í°í™” ë° í…ì„œë¡œ ë³€í™˜í•˜ëŠ” Datasetì„ ì¬ì •ì˜í•œ í´ë˜ìŠ¤ \"\"\"\n","\n","    def __init__(self, max_length=128):\n","        self.max_length = max_length\n","        self.model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","        self.tokenizer = MarianTokenizer.from_pretrained(self.model_name)\n","\n","    # tokenizer ì •ì˜\n","    def tokenizer_function(self, data):\n","        return self.tokenizer(\n","            data,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True\n","        )\n","\n","    # í•™ìŠµì„ ìœ„í•œ Dataset\n","    def get_inputs(self, df):\n","        input_pairs = []  # ëª¨ë¸ì— í•™ìŠµì‹œí‚¬ ë°ì´í„°(í…ì„œ)ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","\n","        for i in range(len(df)):\n","            # input ë° target ë°ì´í„° ì¶”ì¶œ\n","            input_text = df.iloc[i, 0]\n","            target_text = df.iloc[i, 1]\n","\n","            # input ë° target ë°ì´í„° í† í°í™”\n","            input_ids = self.tokenizer_function(input_text)\n","            target_ids = self.tokenizer_function(target_text)\n","\n","            # ëª¨ë¸ì— í•™ìŠµì‹œí‚¬ ë°ì´í„° -> í…ì„œë¡œ ë³€í™˜\n","            input_pair = {'input_ids' : torch.LongTensor(input_ids['input_ids']),\n","                          'attention_mask' : torch.LongTensor(input_ids['attention_mask']),\n","                          'labels' : torch.LongTensor(target_ids['input_ids'])}\n","\n","            input_pairs.append(input_pair)\n","\n","        return input_pairs\n","\n","    # ìƒì„± ë° ì„±ëŠ¥ì¸¡ì •ì˜ ìœ„í•œ Dataset\n","    def get_input_ids(self, df):\n","        input_ids_list = []  # ëª¨ë¸ì— ìƒì„± ë° ì„±ëŠ¥ì¸¡ì •í•  ë°ì´í„°(í…ì„œ)ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","\n","        for i in range(len(df)):\n","            # input ë°ì´í„° ì¶”ì¶œ\n","            input_text = df.iloc[i, 0]\n","\n","            # input ë°ì´í„° í† í°í™”\n","            input_ids = self.tokenizer(input_text, padding=\"max_length\", max_length=self.max_length, truncation=True)[\"input_ids\"]\n","            input_ids_list.append(input_ids)\n","\n","        return torch.tensor(input_ids_list)  # í…ì„œ ë³€í™˜"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":723,"status":"ok","timestamp":1722177284779,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"o7Nd9BlfVytf"},"outputs":[],"source":["# Dataset ì •ì˜\n","custom_dataset = CustomDataset()\n","\n","# Dataset ìƒì„±\n","dataset_train = custom_dataset.get_inputs(train_df)\n","dataset_val = custom_dataset.get_inputs(valid_df)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1722177284779,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"6THiYe0rQSUf","outputId":"debbb6c9-eaa9-447f-d818-c9d9084c04a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset_train len : 350\n"]},{"data":{"text/plain":["{'input_ids': tensor([ 2157,   131,   157,  9986, 16879,   131, 28690,    48, 13572,   253,\n","             9, 15009, 21955, 15604, 16491, 35778, 16149,   163,  7356,  4827,\n","          1085,  5468,   640,    40,  1787,   450,  2771,  1492,  1282,   989,\n","          4646, 34975, 29847,    62,   362, 22946,  1881,   168, 25604,  9870,\n","          1698,  1327,   450,  2771,   162,   541,  2469, 40264,   450,  2771,\n","           234, 36844,   161,     2,     0, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([   57,     9, 11927, 23269,  8473,  1921,     6,  1640,  1438,  7932,\n","          2936,     6,     4,     9, 15077,   649,   897,  7460,   639,     6,\n","             9,  5732,  9561,  1641,  5708,     9,  3520, 16807,    61,    31,\n","             9,  3780,  9432,  2936,   194,    13,    73,  1731,   494,  1132,\n","          3569,   639,     9,  4504, 40977,    10,    26,  1681,  1013,    49,\n","           992,    10,    81,    38,     9,  2188,  1602,     5,  1835,  7932,\n","             9,  7490,     4,  2959,  1681,  1013, 31435,     9, 14434,  3128,\n","             4,  2959,    13,   897, 10488,  1681,   897,   101, 17871,    10,\n","          4225, 11341,     5,   430,  1028,  2730, 10368,   123,  9986,  4225,\n","          2135,  3778,     3,     8,    39,   295,  1487,  7405,  1439,     9,\n","          3520, 16807,     8,  1731,   494,  1132,  3569,   639,     9,  3520,\n","         16807,    26,     4,     9, 11372,   130,     9, 10262,  8283,    38,\n","          1487,  8513,   194,     2,     0, 65000, 65000, 65000])}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] Dataset\n","print(f'dataset_train len : {len(dataset_train)}')\n","dataset_train[0]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1722177284780,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"KlR2xYKTQWxW","outputId":"40f7be6e-24d5-493f-aff4-4b626d48345b"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset_val len : 35\n"]},{"data":{"text/plain":["{'input_ids': tensor([15823, 23428,  7092,  4078,  1034,  4399, 23988, 13652,  1034,     9,\n","         39728,   518,    51,  2341,  1034,   539,    85,  1052,  9194,  7533,\n","           249,   977,   349,   887, 14582,    48,  7297,  1011, 10434,  1046,\n","         23428,    79, 14552,   255,  3975,  5547,  3280,   578,  9355,   151,\n","           161,     2,     0, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([   57,  1495,  8910,     9,  7942, 38564,    20,    15,     4,  2441,\n","          8513,   649,  2936,  3963,  2025,     9,  1132,  2894,  2188,   897,\n","           194,  4874,  9719,  1850,  1053,  2253,  2652,     9,  2135,  6296,\n","          2936,    10,     5,     4,     9,  6009,   992,  9369,   123,   101,\n","          3843,  4268,  1487,  2895,  7613,   639,  8460,  2196,     8,  1495,\n","          2253, 44131,   639,     8, 18923, 28907,    59,   639,   595,  8460,\n","          2196,    10,     3,  1835, 11755,   130,     4,     9,  6229,    26,\n","             9,  6009,   992,  9369,     5,    31,    73,  5259,   194,     9,\n","          2188,  4732,  5566,  9369,  5838,     9,  4257,  1640,  5613,    10,\n","          4268,    68,     4,  1731,  2959,  9631,   977,  4545, 43206,    10,\n","             6,  1835,   101,  1673,   649,  1132, 15489,     2,     0, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000])}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] Dataset\n","print(f'dataset_val len : {len(dataset_val)}')\n","dataset_val[0]"]},{"cell_type":"markdown","metadata":{"id":"WuvpzS9XR2rD"},"source":["## 6. ì‚¬ìš©ì ì •ì˜ CustomModel ì¬ì •ì˜"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177284780,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"zf5e4DQIR15Z"},"outputs":[],"source":["class CustomModel(nn.Module):\n","\n","    \"\"\" fine-tuningí•˜ê¸° ìœ„í•´ pretrained ëª¨ë¸ì¸ MarianMT ëª¨ë¸ ì¬ì •ì˜í•œ í´ë˜ìŠ¤ \"\"\"\n","\n","    def __init__(self, custom_dataset, model_name, decoder_layers=6, dropout=None):\n","        super().__init__()\n","        config = MarianConfig.from_pretrained(model_name)  # ëª¨ë¸ êµ¬ì„±ìš”ì†Œ\n","        config.decoder_layers = decoder_layers  # ë””ì½”ë”\n","        self.custom_dataset = custom_dataset  # ë°ì´í„°ì…‹\n","        self.model = MarianMTModel.from_pretrained(model_name, config = config)  # ëª¨ë¸ ì •ì˜\n","\n","        # dropout\n","        if dropout:\n","            self.model.dropout = dropout\n","\n","        # encoder freezing\n","        for param in self.model.get_encoder().parameters():\n","            param.requires_grad = False\n","\n","        self.batch_size = -1\n","        self.batch_cnt = -1\n","\n","    # ëª¨ë¸ í•™ìŠµ\n","    def train(self, training_args, train_df, valid_df):\n","        # train / validation Dataset ë¡œë“œ\n","        train_dataset = self.custom_dataset.get_inputs(train_df)\n","        valid_dataset = self.custom_dataset.get_inputs(valid_df)\n","\n","        # í•™ìŠµ\n","        trainer = Trainer(\n","            model=self.model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=valid_dataset,\n","        )\n","\n","        trainer.train()\n","\n","    # ëª¨ë¸ ìƒì„±\n","    def generate(self, df):\n","        # ìƒì„± ë° ì„±ëŠ¥ì¸¡ì •ì˜ ìœ„í•œ Dataset ë¡œë“œ\n","        input_ids = self.custom_dataset.get_input_ids(df)\n","\n","        # ë¬¸ì¥ ìƒì„±\n","        outputs = self.model.generate(input_ids.to(device), max_length=128)\n","\n","        # ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜\n","        output_sentences = []\n","        for output in outputs:\n","            output_sentences.append(tokenizer.decode(output, skip_special_tokens=True))\n","\n","        return output_sentences\n","\n","    # batch ë‹¨ìœ„ ì •í™•ë„ ì¸¡ì •(BLEU)\n","    def batch_accuracy(self, df):\n","        self.batch_cnt += 1\n","\n","        # ëª¨ë¸ ìƒì„± ê²°ê³¼\n","        output_sentences = self.generate(df)\n","\n","        # target(ë²ˆì—­ë¬¸)\n","        target_sentences = [sentence for sentence in df['ë²ˆì—­ë¬¸']]\n","\n","        # í˜„ì¬ ë°°ì¹˜ ë¬¸ì¥ ê°œìˆ˜, ì •í™•ë„\n","        batch_sen_cnt, accuracy_cnt =  0, 0\n","\n","        \"\"\"\n","        BLEU: output ë‹¨ì–´ê°€ targetì— í¬í•¨ëœ ì •ë„\n","        ROUGE: target ë‹¨ì–´ê°€ outputì— í¬í•¨ëœ ì •ë„\n","        \"\"\"\n","\n","        # SmoothingFunction ì •ì˜\n","        # smoothing_function = SmoothingFunction().method1  # method1: ê¸°ë³¸ì ì¸ smoothing ë°©ë²•\n","\n","        print(f'### {self.batch_cnt} batch start ###')\n","        for i in range(len(df)):\n","            batch_sen_cnt += 1\n","\n","            output_sentence = output_sentences[i]  # ëª¨ë¸ ìƒì„± ê²°ê³¼(ë²ˆì—­ë¬¸)\n","            target_sentence = target_sentences[i]  # target(ë²ˆì—­ë¬¸)\n","\n","            # ë¬¸ì¥ì„ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n","            candidate = output_sentence.split()   # ìƒì„±ëœ ë¬¸ì¥ì„ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n","            reference = [target_sentence.split()]   # ì°¸ì¡° ë¬¸ì¥(target)ì„ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n","\n","            # 1-gram, 2-gram, 3-gram, 4-gram í‰ê°€\n","            weights = (1.0, 1.0, 1.0, 1.0)\n","\n","            # BLEU ì ìˆ˜ ê³„ì‚°\n","            bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","            accuracy_cnt += bleu_score\n","\n","        # ë°°ì¹˜ ë‹¨ìœ„ í‰ê·  BLEU ì ìˆ˜ ì¸¡ì •\n","        performance = accuracy_cnt / batch_sen_cnt\n","        print(f'{self.batch_cnt} batch BLEU performance : {performance}\\n')\n","\n","        return performance\n","\n","    # # batch ë‹¨ìœ„ ì •í™•ë„ ì¸¡ì •(ë˜‘ê°™ìœ¼ë©´ 1, í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ 0)\n","    # def batch_accuracy(self, df):\n","    #     self.batch_cnt += 1\n","\n","    #     # ëª¨ë¸ ìƒì„± ê²°ê³¼\n","    #     output_sentences = self.generate(df)\n","\n","    #     # target(ë²ˆì—­ë¬¸)\n","    #     target_sentences = [sentence for sentence in df['ë²ˆì—­ë¬¸']]\n","\n","    #     # í˜„ì¬ ë°°ì¹˜ ë¬¸ì¥ ê°œìˆ˜, ì •í™•ë„\n","    #     batch_sen_cnt, accuracy_cnt = 0, 0\n","\n","    #     print(f'### {self.batch_cnt} batch start ###')\n","    #     for i in range(len(df)) :\n","    #         batch_sen_cnt += 1\n","\n","    #         output_sentence = output_sentences[i]  # inputìœ¼ë¡œ ëª¨ë¸ ìƒì„± ê²°ê³¼(ë²ˆì—­ë¬¸)\n","    #         target_sentence = target_sentences[i]  # target(ë²ˆì—­ë¬¸)\n","\n","    #         # ì •í™•ë„ ì¹´ìš´íŠ¸\n","    #         if output_sentence == target_sentence :\n","    #             accuracy_cnt += 1\n","    #         else :\n","    #             self.test_result[0].append(output_sentence)\n","    #             self.test_result[1].append(target_sentence)\n","\n","    #     # batch ë‹¨ìœ„ ì •í™•ë„ ì¸¡ì •\n","    #     performance = accuracy_cnt / batch_sen_cnt\n","    #     print(f'{self.batch_cnt} batch performance : {performance}\\n')\n","\n","    #     return performance\n","\n","    # ì´ ì •í™•ë„ ì¸¡ì •\n","    def total_test_accuracy(self, df, batch_size):\n","        self.batch_size = batch_size\n","        self.batch_cnt = 0\n","        self.test_result = [[], []]\n","\n","        start, end = 0, self.batch_size\n","\n","        performance = 0\n","        while 1:\n","            if start >= len(df):\n","                break\n","\n","            end = min(end, len(df))\n","\n","            # í˜„ì¬ ë°°ì¹˜ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ì—¬ ëˆ„ì \n","            performance += self.batch_accuracy(df[start:end])\n","\n","            start = end  # ì‹œì‘ ì¸ë±ìŠ¤ë¥¼ ë ì¸ë±ìŠ¤ë¡œ ì—…ë°ì´íŠ¸\n","            end += self.batch_size  # ë ì¸ë±ìŠ¤ë¥¼ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì¦ê°€\n","\n","        # ì´ ì •í™•ë„ ì¸¡ì •\n","        performance /= self.batch_cnt\n","        print(f'final performance : {performance}')\n","\n","        return performance\n","\n","    def return_model(self):\n","        return self.model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1722177284781,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"RQ3myBbvhnsa"},"outputs":[],"source":["# ì•„ë˜ ì‹¤í–‰í•˜ì§€ ë§ˆì‹œì˜¤!"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177284782,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"SVj_mUvJhkfO"},"outputs":[],"source":["# ì•„ë˜ ì‹¤í–‰í•˜ì§€ ë§ˆì‹œì˜¤!"]},{"cell_type":"markdown","metadata":{"id":"Lq2BSZAq1xvI"},"source":["## 7. Fine-tuning"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1018214,"status":"ok","timestamp":1722178306861,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"DfGagPn9YY6R","outputId":"c1fc055d-8158-4e13-a04b-d92e5ea365e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:49, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 8.036855140815083e-05\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.000595318985056105\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 2.3651994461892806e-05\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.0002466941701014961\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.00014049407095816048\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 8.87666385669557e-05\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 6.929132510894393e-05\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 9.41364080175138e-06\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.0006024112688210565\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 4.070813455066736e-05\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.00038250431561550724\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.00017490378757383128\n","\n","final performance : 0.0002045439069187099\n","25 epoch performance : 0.0002045439069187099\n","25 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.0008946055189552148\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.0023058814138638556\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.0005853981308964397\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.003668207537738592\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.003983396001330227\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.0008711839345660415\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.0006682297085401975\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.0005604014107392209\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.0009818515620717938\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.0009314942384123361\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.00254358161329247\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.0015924269468752944\n","\n","final performance : 0.0016322215014401402\n","50 epoch performance : 0.0016322215014401402\n","50 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.015141958461599768\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.03720690614776855\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.011865745737870043\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.011329824344093232\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.010030178658256849\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.022536141693621035\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.01160570110766767\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.0034593782379337638\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.008873064074389536\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.040974573005548756\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.02273022694709739\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.016339233735183666\n","\n","final performance : 0.017674411012585853\n","75 epoch performance : 0.017674411012585853\n","75 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.09411389259516051\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.10775029225726486\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.035993365469332586\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.09005791659777525\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.08416035299087475\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.08915232754327258\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.0966790570631373\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.06328220665089607\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.07044720244527193\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.1047130584074243\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.08143235528234564\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.13219412662156219\n","\n","final performance : 0.0874980128270265\n","100 epoch performance : 0.0874980128270265\n","100 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.3138237790408136\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.34447822979165404\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.27228902760698415\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.3561611327771157\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.2663455068668228\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.39099665997370386\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 7 batch start ###\n","7 batch BLEU performance : 0.26611211885231045\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.3144602506510052\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.36958401827940546\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.4180165139994948\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.3488656681475798\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.34488548093361565\n","\n","final performance : 0.3338348655767088\n","125 epoch performance : 0.3338348655767088\n","125 epoch is best model\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:32, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.5507375304135199\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.5990324110180109\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.6004235580545644\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 4 batch start ###\n","4 batch BLEU performance : 0.664938810723498\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.5273016055985253\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.6285646870836775\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.5310965100680582\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.545942180242578\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.6115025072988425\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.5026320594648634\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.5351338136626356\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.6198105650753712\n","\n","final performance : 0.5764263532253454\n","150 epoch performance : 0.5764263532253454\n","150 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:32, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.706641214039298\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7470705973411427\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.7589007670459795\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.6911384773328094\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.7088729450207469\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.7350406930474875\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7309799958459776\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.7485273471678713\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.750105520787913\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.7198793854888217\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.71520738401241\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.6969151237693638\n","\n","final performance : 0.7257732875749853\n","175 epoch performance : 0.7257732875749853\n","175 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.7558844030013456\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7415264984522533\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8186531000067466\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7690759016146937\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.7989855341343919\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8376069290906704\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7707757732777025\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8013166023527436\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.8049200970604161\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.7820778840569884\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8471424616277683\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8213843122386562\n","\n","final performance : 0.7957791247428648\n","200 epoch performance : 0.7957791247428648\n","200 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8046137114103246\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7989026013434323\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8458304660147332\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7803041439456282\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8343776437286646\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8332298380654677\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7154576956497717\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8474668347795755\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.7673694485455979\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.867838681399079\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8800521691738382\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.7928653204768007\n","\n","final performance : 0.8140257128777427\n","225 epoch performance : 0.8140257128777427\n","225 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8567583151054091\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.794135185025688\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8688711417036129\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7903144743674682\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8175429259629624\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8654909120550013\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7830192016651313\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8048734740129435\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.831490201177055\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.8622038556567969\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.9516491642978254\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8465158948141486\n","\n","final performance : 0.8394053954870034\n","250 epoch performance : 0.8394053954870034\n","250 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8412922397602127\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.8215852782487131\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8698891285576218\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.8534746160550709\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8818268394585661\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8263698991113946\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.85138432513369\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8274206289150402\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.8993763205339872\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.9106843749419293\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8468431028899247\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8515713286891146\n","\n","final performance : 0.8568098401912722\n","275 epoch performance : 0.8568098401912722\n","275 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8857185225613569\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.8242985020564572\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8428079739175018\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.8134973015851529\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.768028152492548\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8523013393814376\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.8407412629905997\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.7958590694146356\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.9031515257907201\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.9171484968532532\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8458522511931073\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8077880616398394\n","\n","final performance : 0.8414327049897175\n","300 epoch performance : 0.8414327049897175\n","Tunning Success.\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™”\n","model = CustomModel(custom_dataset, model_name)\n","model.return_model()\n","\n","# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •\n","model_path = \"/content/drive/MyDrive/model/\"\n","\n","# í•™ìŠµ Epoch, Batch, Step ì •ì˜\n","num_train_epochs = 25\n","batch_size = 30\n","step = 500\n","\n","# í•™ìŠµ ë³€ìˆ˜\n","training_args = TrainingArguments(\n","    output_dir=model_path,\n","    overwrite_output_dir=True,\n","    num_train_epochs=num_train_epochs,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    eval_steps=step,\n","    save_steps=step,\n","    logging_steps=step,\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","# ëª¨ë¸ í•™ìŠµ(600 epoch)\n","performance_max = 0\n","try:\n","    for i in range(24):  # 25 * 24 = 600 epoch\n","        model.train(training_args, train_df, valid_df)\n","        performance = model.total_test_accuracy(train_df, batch_size=batch_size)  # ì„±ëŠ¥ì¸¡ì •\n","        print(f'{num_train_epochs * (i+1)} epoch performance : {performance}')\n","\n","        if performance_max < performance:  # í˜„ì¬ ì„±ëŠ¥ì´ ì´ì „ ìµœê³  ì„±ëŠ¥ë³´ë‹¤ ì¢‹ìœ¼ë©´ ëª¨ë¸ ì €ì¥\n","            performance_max = performance\n","            print(f'{num_train_epochs * (i+1)} epoch is best model\\n')\n","            # torch.save(model,\"/content/drive/MyDrive/model/marian_fine_tunned_model_v1_3.pt\")\n","            torch.save(model.return_model().state_dict(), \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\")\n","            print(\"Best model saved.\")\n","        else:\n","            # í˜„ì¬ ì„±ëŠ¥ì´ ì´ì „ ìµœê³  ì„±ëŠ¥ë³´ë‹¤ ì¢‹ì§€ ì•Šìœ¼ë©´ ì´ì „ ëª¨ë¸ë¡œ ì €ì¥í•˜ê³  í•™ìŠµ ì¤‘ë‹¨\n","            print(\"Tunning Success.\")\n","            break\n","\n","except KeyboardInterrupt:\n","    if performance_max > 0:  # ì´ì „ ì„±ëŠ¥ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì €ì¥\n","        # torch.save(model, \"/content/drive/MyDrive/model/marian_fine_tunned_model_v1_3.pt\")\n","        torch.save(model.return_model().state_dict(), \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\")\n","        print(\"Best model saved.\")"]},{"cell_type":"markdown","metadata":{"id":"6Gn7wnaXWJPa"},"source":["## 8. Fine-tunning ê²°ê³¼ í™•ì¸(Train Dataset)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14877,"status":"ok","timestamp":1722179347736,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"L92H75Sc9rnU","outputId":"9c02f1b6-662f-4f19-fa71-8d30b12b7d28"},"outputs":[{"name":"stdout","output_type":"stream","text":["generated_text: The suspension of repayment of the principal of household loans will be implemented in all financial sectors for debtors who are unable to pay off their debts after their income decreases due to COVID-19 damage, and only credit loans and financial loans for the working class are covered.\n","target_text: The suspension of repayment of the principal of household loans will be implemented in all financial sectors for debtors who are unable to pay off their debts after their income decreases due to COVID-19 damage, and only credit loans and financial loans for the working class are covered.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Vice President Lee of Kakao Pay held a press conference and said his future business goal is a paperless society, which aims to expand services that can receive various bills through Kakao Talk platforms.\n","target_text: Vice President Lee of Kakao Pay held a press conference and said his future business goal is a paperless society, which aims to expand services that can receive various bills through Kakao Talk platforms.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Counterpoint Research analyzed that Xiaomi is expanding its influence in China's home turf and global markets under the influence of Flower's sanctions in Europe and Latin America.\n","target_text: Counterpoint Research analyzed that Xiaomi is expanding its influence in China's home turf and global markets under the influence of Flower's sanctions in Europe and Latin America.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Super chaebol institutional investors such as BlackRock and Vanguard should be allowed to operate according to the standards of the corporation system principle, not moral standards.\n","target_text: Super chaebol institutional investors such as BlackRock and Vanguard should be allowed to operate according to the standards of the corporation system principle, not moral standards.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Naver will launch a subscription service that allows users to use Naver's major services if they pay a monthly subscription fee.\n","target_text: Naver will launch a subscription service that allows users to use Naver's major services if they pay a monthly subscription fee.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: The death toll in Daegu increased to 54 as the man, who had an underlying disease, died at Kyungpook National University Hospital due to cardiac arrest.\n","target_text: The death toll in Daegu increased to 54 as the man, who had an underlying disease, died at Kyungpook National University Hospital due to cardiac arrest.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Among those from the Blue House who were candidates for the 21st general election, 64% of the total were certain, confirmed, and likely candidates, but some were in a close race.\n","target_text: Among those from the Blue House who were candidates for the 21st general election, 64% of the total were certain, confirmed, and likely candidates, but some were in a close race.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Concerned about COVID-19, the Incheon Metropolitan Government decided to establish an online grave and memorial service at Incheon Family Park, the largest commercial facility in Incheon.\n","target_text: Concerned about COVID-19, the Incheon Metropolitan Government decided to establish an online grave and memorial service at Incheon Family Park, the largest commercial facility in Incheon.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Aerobic exercises such as jogging, walking, swimming, cycling, and light hiking can lower triglycerides and cholesterol levels that cause arteriosclerosis for arterial health care.\n","target_text: Aerobic exercises such as jogging, walking, swimming, cycling, and light hiking can lower triglycerides and cholesterol levels that cause arteriosclerosis for arterial health care.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Cheong Wa Dae has decided to accept all suggestions from the business community presented at the meeting of the business community in response to COVID-19 and promptly implement follow-up measures.\n","target_text: Cheong Wa Dae has decided to accept all suggestions from the business community presented at the meeting of the business community in response to COVID-19 and promptly implement follow-up measures.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: In addition, the Democratic Party of Korea chose for citizens as a proportional coalition platform, laying the groundwork for a proportional coalition party, and the basic income party and the transition of the times joined, excluding the political reform coalition.\n","target_text: In addition, the Democratic Party of Korea chose for citizens as a proportional coalition platform, laying the groundwork for a proportional coalition party, and the basic income party and the transition of the times joined, excluding the political reform coalition.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Director Park challenged the movie \"Hill of the Wind\" to a wandering screening that visited audiences all over the country.\n","target_text: Director Park challenged the movie \"Hill of the Wind\" to a wandering screening that visited audiences all over the country.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: At the emergency economic meeting, President Moon announced that he would implement emergency financial measures worth 50 trillion won as a package program for people's livelihoods and financial stability.\n","target_text: At the emergency economic meeting, President Moon announced that he would implement emergency financial measures worth 50 trillion won as a package program for people's livelihoods and financial stability.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: If the ventilation in the house is poor, the smell of ammonia and acetic acid in the bowel movement stresses cats, and it is the air purifier that is considered a solution to this.\n","target_text: If the ventilation in the house is poor, the smell of ammonia and acetic acid in the bowel movement stresses cats, and it is the air purifier that is considered a solution to this.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: The competition held amid the COVID-19 incident was unfamiliar to Bae as he played without a gallery.\n","target_text: The competition held amid the COVID-19 incident was unfamiliar to Bae as he played without a gallery.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","==================================================\n","Average BLEU Score: 1.0\n"]}],"source":["# [Test] Fine-tunning ëª¨ë¸ë¡œ ìƒì„± ë° íƒ€ì¼“ í‰ê°€(train dataset)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","data_path = '/content/drive/MyDrive/'\n","train_df = pd.read_excel(data_path+'sum_tran_train.xlsx')[:15]\n","\n","# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","model = MarianMTModel.from_pretrained(model_name)\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# ì €ì¥ëœ ëª¨ë¸(state dict) ë¶ˆëŸ¬ì˜¤ê¸°\n","model_path = \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\"\n","model.load_state_dict(torch.load(model_path))\n","\n","# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n","model.to(device)\n","model.eval()\n","\n","bleu_scores = []\n","for i in range(len(train_df)):\n","    inputs = tokenizer(train_df.iloc[i, 0], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    attention_mask = inputs[\"attention_mask\"].to(device)\n","\n","    # ìƒì„± ë° ë³€í™˜\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # target\n","    target_text = train_df.iloc[i, 1]\n","\n","    print(f\"generated_text: {generated_text}\")\n","    print(f\"target_text: {target_text}\")\n","    print(f\"Match: {generated_text == target_text}\\n\")\n","\n","    # 1-gram, 2-gram, 3-gram, 4-gram í‰ê°€ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜\n","    weights = (0.25, 0.25, 0.25, 0.25)\n","\n","    # BLEU ì ìˆ˜ ê³„ì‚°\n","    candidate = generated_text.split()\n","    reference = [target_text.split()]\n","    bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","    bleu_scores.append(bleu_score)\n","    print(f\"BLEU Score: {bleu_score}\\n\")\n","    print(\"--------------------------------------------------\")\n","\n","avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(\"==================================================\")\n","print(f\"Average BLEU Score: {avg_bleu_score}\")"]},{"cell_type":"markdown","metadata":{"id":"Ml-yhf9vxui8"},"source":["## 9. Fine-tunning ê²°ê³¼ í™•ì¸(Validation Dataset)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16420,"status":"ok","timestamp":1722179374614,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"XnsR1LY4czeb","outputId":"85836df9-82f1-46b4-cbfb-a2084d7fa44f"},"outputs":[{"name":"stdout","output_type":"stream","text":["generated_text: It is oil to covernment the government's plan to enter the presidential and oppositional leader's party and lead measures to service events at the early 14 weeks of accountry.\n","target_text: The main point is that the government has announced legislative amendments to the abortion-related criminal law and maternal and child health laws, paving the way for abortion to be allowed unconditionally if requested by the first 14 weeks of pregnancy.\n","Match: False\n","\n","BLEU Score: 1.4875769488812793e-78\n","\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["generated_text: The Japan Mindropolitan Government revealed IAEA's announced crisis that is dayly imported in the worlds, causing disruptional prevention and expanding unique through on confirmed expression of political supply.\n","target_text: The Japanese government drew the IAEA's interpretation that marine discharge is routinely carried out around the world, insisting on the legitimacy of the discharge and highlighting transparent efforts to disclose information on the discharge of contaminated water.\n","Match: False\n","\n","BLEU Score: 9.65821029960698e-232\n","\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["generated_text: The hidden Choi Motors' Office is increasing, and the number of HUV is not in an official.\n","target_text: With the growing popularity of SUVs, Hyundai Motor's Sonata, which was called the national car, is not as popular as before.\n","Match: False\n","\n","BLEU Score: 4.1054243192424385e-155\n","\n","--------------------------------------------------\n","generated_text: Due to the time of debtinishment, Daek, which conducted his experience, which has been a diplobal instead of the company man, which has been a Daeju Church-kyeong team, and the  tastropany of Lee Jung-kyeung, a movicial company team that the administ\n","target_text: In fact, Hong, who worked as an in-house TOEIC instructor for a company during the globalization of the 90s, wrote the first draft, and director Lee's English TOEIC class, which was mixed with fictional settings, was released.\n","Match: False\n","\n","BLEU Score: 3.9421554930094576e-155\n","\n","--------------------------------------------------\n","generated_text: In the absence of the National Assembly and the National Assembly, Gang said, \"We are expected to have a contract spready that can receive the return of company while whiles.\"\n","target_text: Regarding the sexual harassment of embassies in New Zealand and Nigeria, Kang said, \"While I feel the limitations of leadership, it is the result of the Ministry of Foreign Affairs having a system that allows me to report freely report.\"\n","Match: False\n","\n","BLEU Score: 3.5840639204446147e-155\n","\n","--------------------------------------------------\n","generated_text: COVID-19 spreads against the number of confirmed with the sales of people and of expectary union, which has been more family enough an day.\n","target_text: The Chuseok holiday was more depressing than any other year due to the spread of COVID-19, which is directly related to the safety and respect for life of the people, and the murder of public officials.\n","Match: False\n","\n","BLEU Score: 8.396161215621529e-232\n","\n","--------------------------------------------------\n","generated_text: The betweening between City Commission was unable to know what was acquired in the longdang Dedong Park that was reignited by the confirming of the ASF virtually, which has been due to the concern of the National AssF visitive Party, which has been recorded exercessive.\n","target_text: The resumption of tourism, which was suspended due to the continued detection of the ASF virus in wild boars around the civilian control line, was unknown, and the co-chairman of the Yeoncheon Imjin River Citizens' Network was sorry.\n","Match: False\n","\n","BLEU Score: 2.5429199679442697e-78\n","\n","--------------------------------------------------\n","generated_text: As the nationwide of confirmation has been played by the China's representative national community and the National Committee, where the winding pandar is occurring due to the situation of COVID-19.\n","target_text: Holding the National People's Congress and the National Political Consultative Conference, which were postponed by China, the world is groaning over the COVID-19 incident, raising a fanfare of victory.\n","Match: False\n","\n","BLEU Score: 2.013654296748599e-78\n","\n","--------------------------------------------------\n","generated_text: Experts established that the streets of COVID-19 in Korea has increased the influence of cultural disasters, culture culture, and systems.\n","target_text: Experts predicted that the low number of COVID-19 confirmed cases in India is affected by the hot and humid climate, vegetarian food culture, and spices.\n","Match: False\n","\n","BLEU Score: 5.997822887308343e-155\n","\n","--------------------------------------------------\n","generated_text: Cleading the Seoul District Court, Lee has been received at the Korean Ministry and the Moinistry of Gyeonggi Province and the Ministry of Gyeon-gu, and it was revealed at an official state book, first increasing the artifiortain.\n","target_text: Laundry, set in Daldongne, Seoul, won awards at the Korean Musical Grand Prize and The Musical Awards, and the script was published for the first time in middle and high school textbooks.\n","Match: False\n","\n","BLEU Score: 1.945240729393877e-78\n","\n","--------------------------------------------------\n","generated_text: The sorry leaded an experience caller's representence to the ballening at Hotae Motors' when 17 players established their special instead for 100 days.\n","target_text: Soso Stationery displayed notes of 17 people writing down their interests for 100 days throughout Standard A's showroom so that visitors could see them.\n","Match: False\n","\n","BLEU Score: 4.258603586864609e-155\n","\n","--------------------------------------------------\n","generated_text: Handtohomide, which had a taxi transporter to the house's houseion, was emerging between the ruling companies after regional, but the bentz management has said heavy.\n","target_text: The home-to-home service, which picks up the car to the customer's house and returns it after repair, was higher in unit price than the general maintenance plant, but a large number of Mercedes-Benz vehicle owners flocked.\n","Match: False\n","\n","BLEU Score: 3.3620599903439287e-155\n","\n","--------------------------------------------------\n","generated_text: It is possibility that China's exercise of strengthing of COVID-19 will be implemented in Seoul and play into Chinaul, which will introduc a strengthly suspictment scenarming around to change the spread of COVID-19.\n","target_text: Chinese authorities are expected to implement strong measures in Heilongjiang Province, including the death penalty for those who deliberately spread the coronavirus epidemic, and expand them across China.\n","Match: False\n","\n","BLEU Score: 1.136638440788832e-231\n","\n","--------------------------------------------------\n","generated_text: In a survey play local players in Cheon's announcement, confirmations caused due to the resulting party's country, controversy are raising confirmed against its effect.\n","target_text: The theory of uselessness of local currency contained in the report released by Cho Se-yeon is intensifying controversy over the effectiveness of local currency, starting with criticism from the governor of Gyeonggi Province.\n","Match: False\n","\n","BLEU Score: 8.00037014003153e-232\n","\n","--------------------------------------------------\n","generated_text: Due to concernal continuation, domestic markets are treated as screenctions and drugs, which is argantly arounding polices all over the country, but they do not expect to be removed.\n","target_text: Wild animals are being used for decoration or medicine through illegal capture, so poaching is strongly regulated around the world, but it does not seem to be eradicated.\n","Match: False\n","\n","BLEU Score: 4.545249402532287e-155\n","\n","--------------------------------------------------\n","==================================================\n","Average BLEU Score: 5.326261295312016e-79\n"]}],"source":["# [Test] Fine-tunning ëª¨ë¸ë¡œ ìƒì„± ë° íƒ€ì¼“ í‰ê°€(valid dataset)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","data_path = '/content/drive/MyDrive/'\n","valid_df = pd.read_excel(data_path+'sum_tran_valid.xlsx')[:15]\n","\n","# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","model = MarianMTModel.from_pretrained(model_name)\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# ì €ì¥ëœ ëª¨ë¸(state dict) ë¶ˆëŸ¬ì˜¤ê¸°\n","model_path = \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\"\n","model.load_state_dict(torch.load(model_path))\n","\n","# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n","model.to(device)\n","model.eval()\n","\n","bleu_scores = []\n","for i in range(len(valid_df)):\n","    inputs = tokenizer(valid_df.iloc[i, 0], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    attention_mask = inputs[\"attention_mask\"].to(device)\n","\n","    # ìƒì„± ë° ë³€í™˜\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # target\n","    target_text = valid_df.iloc[i, 1]\n","\n","    print(f\"generated_text: {generated_text}\")\n","    print(f\"target_text: {target_text}\")\n","    print(f\"Match: {generated_text == target_text}\\n\")\n","\n","    # 1-gram, 2-gram, 3-gram, 4-gram í‰ê°€ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜\n","    weights = (0.25, 0.25, 0.25, 0.25)\n","\n","    # BLEU ì ìˆ˜ ê³„ì‚°\n","    candidate = generated_text.split()\n","    reference = [target_text.split()]\n","    bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","    bleu_scores.append(bleu_score)\n","    print(f\"BLEU Score: {bleu_score}\\n\")\n","    print(\"--------------------------------------------------\")\n","\n","avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(\"==================================================\")\n","print(f\"Average BLEU Score: {avg_bleu_score}\")"]},{"cell_type":"markdown","metadata":{"id":"2iyMkN7t5AVW"},"source":["#### ë‚´ìš© ìš”ì•½ & ê²°ë¡ : ì§€ë‚œ í”„ë¡œì íŠ¸ ëª¨ë¸ íŠœë‹ì— BLEU ì„±ëŠ¥ì¸¡ì •ì„ ì¶”ê°€í•˜ì—¬ ë³µìŠµí•˜ê³ ì í–ˆë‹¤. ê·¸ë˜ì„œ ì‹œê°„ ë‹¨ì¶• ë° ì»´í“¨íŒ… ìì› ì ˆì•½ì„ ìœ„í•´ ì ì€ ì–‘ì˜ train ë°ì´í„°ë¡œ ëª¨ë¸ì„ íŠœë‹í–ˆë‹¤. í•˜ì§€ë§Œ ê²°ê³¼ëŠ” ëª¨ë¸ì´ train ë°ì´í„°ì—ë§Œ ê³¼ì í•©ë˜ì—ˆë‹¤. ë”°ë¼ì„œ íŠœë‹ëœ ëª¨ë¸ì€ í•™ìŠµí•œ train ë°ì´í„°ì˜ íŒ¨í„´ì´ valid ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í–ˆê³  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ë” ë§ì€ ë°ì´í„°ë¡œ íŒ¨í„´ì„ í•™ìŠµì‹œì¼œí•¨ì„ ëŠê¼ˆë‹¤."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01f9b1bbab5940e89f4ede691f449186":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48cb922e710416aaa9cb98320114660","placeholder":"â€‹","style":"IPY_MODEL_842391b85c1344bb9d5c01f87db6af90","value":"tokenizer_config.json:â€‡100%"}},"0200f3ffdb144b46ab22031e180d42c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_827721f0786e4a4eaeab5ab1350452c5","max":813126,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5fd3bce32644150b5edddfac644c4ca","value":813126}},"0563b2f5e5ee4d47bce6219d7403a22b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8846a7d62c4bfdaa586a9b3dd8f38e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efdac02a822460daf5f1fc79da062ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6011c3f1a2fc4193b25cf1402f1da524","IPY_MODEL_26180c7a68f3446b9cc2c0f5959b0cbe","IPY_MODEL_3ccda280f6564891a3168bed90d66965"],"layout":"IPY_MODEL_ad8fcdb8b5b342bab2841a5ed577987b"}},"12e0b17dd4eb47019ba73f8c822f2d72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"139be2cc5a4c41f6b59cad4b28396cb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"181193808d154ab6ab06139a1431a45d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_369b7f4ccb9645a5916ad175eeecca45","placeholder":"â€‹","style":"IPY_MODEL_a8da0773f20543fe9db10b77a13b3cf7","value":"target.spm:â€‡100%"}},"1a969522b87942689a54999b73282fea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24677bc16fb749a0ab04dd1c8cb1c0eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8846a7d62c4bfdaa586a9b3dd8f38e","max":312087009,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d756e78768d420ea1390d0b56ea14db","value":312087009}},"26180c7a68f3446b9cc2c0f5959b0cbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb8d0dffdfec4ed2bbe97c59708418b7","max":1394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c3d62b797647af9ee1a353a18ffe7e","value":1394}},"2f4afbbce8f1493d9bad76ec095547e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e8f5a03dec64cf0b7b1f740fb4348be","IPY_MODEL_b43cc672daf14d888c88b77bea3f8491","IPY_MODEL_8f75a9e777f34f639968891bc6b29782"],"layout":"IPY_MODEL_6e04e4df1f8346b993ef3ea0fd5ba650"}},"3637fb87d5034918b35635ba21b94b72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"369b7f4ccb9645a5916ad175eeecca45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3793225c8851405ba0c5e316562edf7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ccda280f6564891a3168bed90d66965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3793225c8851405ba0c5e316562edf7b","placeholder":"â€‹","style":"IPY_MODEL_4afeb784e45c489383c420242e6c6b81","value":"â€‡1.39k/1.39kâ€‡[00:00&lt;00:00,â€‡107kB/s]"}},"45fcbdb03e2d41af8f71ddb313375d4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afeb784e45c489383c420242e6c6b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e594b68d5464ddd918f753bafe1ed96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8f5a03dec64cf0b7b1f740fb4348be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc08c6ebfa944e2aa53b82dc3068292","placeholder":"â€‹","style":"IPY_MODEL_d4cddfedced5416f81e4cf4c57136035","value":"source.spm:â€‡100%"}},"5110cd60952b40788becef79b0c96717":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514a9ed5e4834fe09f3019e98e970b09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c3d62b797647af9ee1a353a18ffe7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5af2c3aa4b564bdfb9fcdd6d554ec233":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc18f7dba0b749b6bc3c34724aa70a8c","IPY_MODEL_24677bc16fb749a0ab04dd1c8cb1c0eb","IPY_MODEL_e29b3eac44c745a195b9f7bea16e9944"],"layout":"IPY_MODEL_7dce201b10dd48ca94e992447150d535"}},"5b4dc50063b04d5a93227125982b2e94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d756e78768d420ea1390d0b56ea14db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6011c3f1a2fc4193b25cf1402f1da524":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_514a9ed5e4834fe09f3019e98e970b09","placeholder":"â€‹","style":"IPY_MODEL_de3015d0242c43dba3f491b06510bebc","value":"config.json:â€‡100%"}},"6343603066794320b2fbb17a1d19c64d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b26edd9dd91f405391f9989f4383b451","IPY_MODEL_c28b94deafe34d1389a10fe0dfeedd54","IPY_MODEL_cb1e0f6451e944029b250ec415e75a7b"],"layout":"IPY_MODEL_45fcbdb03e2d41af8f71ddb313375d4b"}},"6591aed40e7543b0820b0a6e7c8d2a2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_181193808d154ab6ab06139a1431a45d","IPY_MODEL_0200f3ffdb144b46ab22031e180d42c3","IPY_MODEL_727ba9717fc249648919f0f4a0f45260"],"layout":"IPY_MODEL_3637fb87d5034918b35635ba21b94b72"}},"6e04e4df1f8346b993ef3ea0fd5ba650":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727ba9717fc249648919f0f4a0f45260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5110cd60952b40788becef79b0c96717","placeholder":"â€‹","style":"IPY_MODEL_d3d195e65ac3439aae7fb9b060b9f129","value":"â€‡813k/813kâ€‡[00:00&lt;00:00,â€‡926kB/s]"}},"72e6f83dd4df475082135ba9befc977c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75604c9279ab4628bedbe0b10aa9c1be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1162b31f6c34cd1b7f139a4a462a45f","IPY_MODEL_f9139877639445b28a900f9e1de7eb29","IPY_MODEL_c45dac4045fc47b2a5d385b403551c85"],"layout":"IPY_MODEL_0563b2f5e5ee4d47bce6219d7403a22b"}},"7771afadf5c548bcacf3b7cdf04b2965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01f9b1bbab5940e89f4ede691f449186","IPY_MODEL_ab9f7fdcbdaa4e19b015afcb404e65ee","IPY_MODEL_f378be1fd1e94f7383802db7542f651d"],"layout":"IPY_MODEL_da15cd42ccdc445ab7bd616f5b485bbd"}},"7dce201b10dd48ca94e992447150d535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"827721f0786e4a4eaeab5ab1350452c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"842391b85c1344bb9d5c01f87db6af90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"893af6876a6544ed8710d2f578c4cd17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f75a9e777f34f639968891bc6b29782":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_962b13e90d164805ad4d2fda6f8518d7","placeholder":"â€‹","style":"IPY_MODEL_b0d69b5925b248838591a13850419f00","value":"â€‡842k/842kâ€‡[00:00&lt;00:00,â€‡962kB/s]"}},"962b13e90d164805ad4d2fda6f8518d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc08c6ebfa944e2aa53b82dc3068292":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6db92ad600c4ab6b5e22ac2b9d63aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8da0773f20543fe9db10b77a13b3cf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab9f7fdcbdaa4e19b015afcb404e65ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7db8133f5aa4afab4ac2e1926707f19","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6db92ad600c4ab6b5e22ac2b9d63aca","value":44}},"ad8fcdb8b5b342bab2841a5ed577987b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0d69b5925b248838591a13850419f00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b26edd9dd91f405391f9989f4383b451":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e594b68d5464ddd918f753bafe1ed96","placeholder":"â€‹","style":"IPY_MODEL_72e6f83dd4df475082135ba9befc977c","value":"generation_config.json:â€‡100%"}},"b2b4aa9fac06489bb1cdc4e8a272d260":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43cc672daf14d888c88b77bea3f8491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce5de4c3598448228f90e2cc60c68302","max":841805,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12e0b17dd4eb47019ba73f8c822f2d72","value":841805}},"bb8d0dffdfec4ed2bbe97c59708418b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc09af2b929340999a32301295a78348":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c28b94deafe34d1389a10fe0dfeedd54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15dffeb454c4dc9a766cb05aa074bd6","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_893af6876a6544ed8710d2f578c4cd17","value":293}},"c45dac4045fc47b2a5d385b403551c85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a969522b87942689a54999b73282fea","placeholder":"â€‹","style":"IPY_MODEL_139be2cc5a4c41f6b59cad4b28396cb0","value":"â€‡1.72M/1.72Mâ€‡[00:00&lt;00:00,â€‡7.14MB/s]"}},"cb1e0f6451e944029b250ec415e75a7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede84c66848545378235d83b7d9e8faf","placeholder":"â€‹","style":"IPY_MODEL_de72e131915544e9a728edaaa1ac68ef","value":"â€‡293/293â€‡[00:00&lt;00:00,â€‡25.3kB/s]"}},"ce5de4c3598448228f90e2cc60c68302":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce6dfc1b1e484ff286dad5b5648ee7b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1162b31f6c34cd1b7f139a4a462a45f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce6dfc1b1e484ff286dad5b5648ee7b5","placeholder":"â€‹","style":"IPY_MODEL_f85b18fef9c842c583c2c11688b4fed0","value":"vocab.json:â€‡100%"}},"d3d195e65ac3439aae7fb9b060b9f129":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d48cb922e710416aaa9cb98320114660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4cddfedced5416f81e4cf4c57136035":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d59047c3687b4812b7891a9668cbed17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6253f9cfe68460cbcfec407997254e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7db8133f5aa4afab4ac2e1926707f19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8e453789e0848e3a684ed9dc4b73f5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da15cd42ccdc445ab7bd616f5b485bbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc18f7dba0b749b6bc3c34724aa70a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b4dc50063b04d5a93227125982b2e94","placeholder":"â€‹","style":"IPY_MODEL_d59047c3687b4812b7891a9668cbed17","value":"pytorch_model.bin:â€‡100%"}},"de3015d0242c43dba3f491b06510bebc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de72e131915544e9a728edaaa1ac68ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29b3eac44c745a195b9f7bea16e9944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6253f9cfe68460cbcfec407997254e0","placeholder":"â€‹","style":"IPY_MODEL_f1a8f61b88d94d748dd39adb0cd060e3","value":"â€‡312M/312Mâ€‡[00:01&lt;00:00,â€‡236MB/s]"}},"e4fd9a73d3fb4621ac01bd640da8d9a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5fd3bce32644150b5edddfac644c4ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ede84c66848545378235d83b7d9e8faf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15dffeb454c4dc9a766cb05aa074bd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a8f61b88d94d748dd39adb0cd060e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f378be1fd1e94f7383802db7542f651d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2b4aa9fac06489bb1cdc4e8a272d260","placeholder":"â€‹","style":"IPY_MODEL_d8e453789e0848e3a684ed9dc4b73f5d","value":"â€‡44.0/44.0â€‡[00:00&lt;00:00,â€‡3.42kB/s]"}},"f85b18fef9c842c583c2c11688b4fed0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9139877639445b28a900f9e1de7eb29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc09af2b929340999a32301295a78348","max":1719866,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4fd9a73d3fb4621ac01bd640da8d9a4","value":1719866}}}}},"nbformat":4,"nbformat_minor":0}
