{"cells":[{"cell_type":"markdown","metadata":{"id":"fLdDdiCWTuW-"},"source":["## 1. 드라이브 마운트"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23598,"status":"ok","timestamp":1722177200464,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"mQKDlSmxVVr3","outputId":"fb710d23-7f47-48bd-e93a-4490e0fa6a71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"3dT4v3a_aZMi"},"source":["## 2. 필요한 패키지 install & import"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59048,"status":"ok","timestamp":1722177259503,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"nsKTJfE8VgNK","outputId":"1f8fd5bd-fe73-4f32-e197-65a997adbe10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.5.15)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.4)\n","Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sacremoses\n","Successfully installed sacremoses-0.1.1\n"]}],"source":["!pip install accelerate>=0.20.1\n","!pip install torch\n","!pip install transformers\n","# !pip install evaluate\n","!pip install nltk\n","!pip install sentencepiece\n","!pip install sacremoses"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9361,"status":"ok","timestamp":1722177268851,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"VcgWlnZLA4Ex"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import (\n","    MarianTokenizer,\n","    MarianMTModel,\n","    MarianConfig,\n","    Trainer,\n","    TrainingArguments,\n",")\n","# import evaluate\n","\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","import pandas as pd\n","import random"]},{"cell_type":"markdown","metadata":{"id":"a5rwJChqHobs"},"source":["## 3. 데이터 로드(train:validation = 9:1)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1815,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"K4uY9GJLVhG4"},"outputs":[],"source":["# 데이터 경로\n","data_path = '/content/drive/MyDrive/'\n","\n","# train / validation 데이터파일 불러오기\n","train_df = pd.read_excel(data_path+'sum_tran_train.xlsx')\n","valid_df = pd.read_excel(data_path+'sum_tran_valid.xlsx')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"lDFob6h2Vt4R","outputId":"b536725d-a04c-4fa2-a7ba-98fa441ef92e"},"outputs":[{"data":{"text/plain":["((350, 2), (35, 2))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] 데이터 확인\n","train_df.shape, valid_df.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177270635,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"A1H1IR5ZWgpe","outputId":"1d99998e-eda6-4ca3-ace1-6a280c2879a8"},"outputs":[{"data":{"text/plain":["(                                                  원문  \\\n"," 0  코로나19 피해로 소득이 감소해 생계비를 빼고 나면 빚을 갚기 어려운 채무자를 위해...   \n"," 1  카카오페이 이 부사장은 기자간담회를 열고 향후 사업 목표가 종이 없는 사회라고 밝혔...   \n"," 2  샤오미가 유럽과 중남미 등에서 화훼이의 제재를 틈타 중국 안방과 글로벌 시장에서 영...   \n"," 3  블랙록·뱅가드 등의 초재벌 기관투자자들은 도덕적 기준이 아닌 주식회사제도 원칙의 기...   \n"," 4  네이버가 매달 구독료를 내면 네이버의 주요 서비스를 쓸 수 있는 구독 서비스를 시작한다.   \n"," \n","                                                  번역문  \n"," 0  The suspension of repayment of the principal o...  \n"," 1  Vice President Lee of Kakao Pay held a press c...  \n"," 2  Counterpoint Research analyzed that Xiaomi is ...  \n"," 3  Super chaebol institutional investors such as ...  \n"," 4  Naver will launch a subscription service that ...  ,\n","                                                   원문  \\\n"," 0  정부가 낙태 관련 형법·모자보건법 개정안을 입법 예고하며 임신 초기인 14주까지 본...   \n"," 1  일본 정부는 해양 방출은 전 세계에서 일상적으로 실시되고 있다는 IAEA의 해석을 ...   \n"," 2    SUV의 인기가 높아지며 국민차로 불리던 현대자동차 쏘나타의 인기가 예전 같지 않다.   \n"," 3  실제 90넌대 글로벌화 시기 모 기업의 사내 토익반 강사로 일했던 홍 작가 자신의 ...   \n"," 4  뉴질랜드와 나이지리아 대사관 성추행 사건에 대해 강 장관은 리더십의 한계를 느끼는 ...   \n"," \n","                                                  번역문  \n"," 0  The main point is that the government has anno...  \n"," 1  The Japanese government drew the IAEA's interp...  \n"," 2  With the growing popularity of SUVs, Hyundai M...  \n"," 3  In fact, Hong, who worked as an in-house TOEIC...  \n"," 4  Regarding the sexual harassment of embassies i...  )"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] 데이터 확인\n","train_df.head(), valid_df.head()"]},{"cell_type":"markdown","metadata":{"id":"dBNWzu5RHuJ1"},"source":["## 4. 사용할 Model, Tokenizer 정의"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351,"referenced_widgets":["7771afadf5c548bcacf3b7cdf04b2965","01f9b1bbab5940e89f4ede691f449186","ab9f7fdcbdaa4e19b015afcb404e65ee","f378be1fd1e94f7383802db7542f651d","da15cd42ccdc445ab7bd616f5b485bbd","d48cb922e710416aaa9cb98320114660","842391b85c1344bb9d5c01f87db6af90","d7db8133f5aa4afab4ac2e1926707f19","a6db92ad600c4ab6b5e22ac2b9d63aca","b2b4aa9fac06489bb1cdc4e8a272d260","d8e453789e0848e3a684ed9dc4b73f5d","2f4afbbce8f1493d9bad76ec095547e6","4e8f5a03dec64cf0b7b1f740fb4348be","b43cc672daf14d888c88b77bea3f8491","8f75a9e777f34f639968891bc6b29782","6e04e4df1f8346b993ef3ea0fd5ba650","9bc08c6ebfa944e2aa53b82dc3068292","d4cddfedced5416f81e4cf4c57136035","ce5de4c3598448228f90e2cc60c68302","12e0b17dd4eb47019ba73f8c822f2d72","962b13e90d164805ad4d2fda6f8518d7","b0d69b5925b248838591a13850419f00","6591aed40e7543b0820b0a6e7c8d2a2c","181193808d154ab6ab06139a1431a45d","0200f3ffdb144b46ab22031e180d42c3","727ba9717fc249648919f0f4a0f45260","3637fb87d5034918b35635ba21b94b72","369b7f4ccb9645a5916ad175eeecca45","a8da0773f20543fe9db10b77a13b3cf7","827721f0786e4a4eaeab5ab1350452c5","e5fd3bce32644150b5edddfac644c4ca","5110cd60952b40788becef79b0c96717","d3d195e65ac3439aae7fb9b060b9f129","75604c9279ab4628bedbe0b10aa9c1be","d1162b31f6c34cd1b7f139a4a462a45f","f9139877639445b28a900f9e1de7eb29","c45dac4045fc47b2a5d385b403551c85","0563b2f5e5ee4d47bce6219d7403a22b","ce6dfc1b1e484ff286dad5b5648ee7b5","f85b18fef9c842c583c2c11688b4fed0","bc09af2b929340999a32301295a78348","e4fd9a73d3fb4621ac01bd640da8d9a4","1a969522b87942689a54999b73282fea","139be2cc5a4c41f6b59cad4b28396cb0","0efdac02a822460daf5f1fc79da062ec","6011c3f1a2fc4193b25cf1402f1da524","26180c7a68f3446b9cc2c0f5959b0cbe","3ccda280f6564891a3168bed90d66965","ad8fcdb8b5b342bab2841a5ed577987b","514a9ed5e4834fe09f3019e98e970b09","de3015d0242c43dba3f491b06510bebc","bb8d0dffdfec4ed2bbe97c59708418b7","58c3d62b797647af9ee1a353a18ffe7e","3793225c8851405ba0c5e316562edf7b","4afeb784e45c489383c420242e6c6b81","5af2c3aa4b564bdfb9fcdd6d554ec233","dc18f7dba0b749b6bc3c34724aa70a8c","24677bc16fb749a0ab04dd1c8cb1c0eb","e29b3eac44c745a195b9f7bea16e9944","7dce201b10dd48ca94e992447150d535","5b4dc50063b04d5a93227125982b2e94","d59047c3687b4812b7891a9668cbed17","0b8846a7d62c4bfdaa586a9b3dd8f38e","5d756e78768d420ea1390d0b56ea14db","d6253f9cfe68460cbcfec407997254e0","f1a8f61b88d94d748dd39adb0cd060e3","6343603066794320b2fbb17a1d19c64d","b26edd9dd91f405391f9989f4383b451","c28b94deafe34d1389a10fe0dfeedd54","cb1e0f6451e944029b250ec415e75a7b","45fcbdb03e2d41af8f71ddb313375d4b","4e594b68d5464ddd918f753bafe1ed96","72e6f83dd4df475082135ba9befc977c","f15dffeb454c4dc9a766cb05aa074bd6","893af6876a6544ed8710d2f578c4cd17","ede84c66848545378235d83b7d9e8faf","de72e131915544e9a728edaaa1ac68ef"]},"executionInfo":{"elapsed":13455,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"WSQ6VN52VjRR","outputId":"66992f98-dbf9-4392-dd23-0a8d9855c626"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7771afadf5c548bcacf3b7cdf04b2965","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f4afbbce8f1493d9bad76ec095547e6","version_major":2,"version_minor":0},"text/plain":["source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6591aed40e7543b0820b0a6e7c8d2a2c","version_major":2,"version_minor":0},"text/plain":["target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75604c9279ab4628bedbe0b10aa9c1be","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0efdac02a822460daf5f1fc79da062ec","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5af2c3aa4b564bdfb9fcdd6d554ec233","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6343603066794320b2fbb17a1d19c64d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# 모델명\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","\n","# 토크나이저 정의\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# 모델 정의\n","model = MarianMTModel.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"ZJ_92GVzjrHh","outputId":"768ff4ae-0681-46b2-dcba-b4c62f809e90"},"outputs":[{"name":"stdout","output_type":"stream","text":["MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-ko-en', vocab_size=65001, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t65000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","} MarianMTModel(\n","  (model): MarianModel(\n","    (shared): Embedding(65001, 512, padding_idx=65000)\n","    (encoder): MarianEncoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianEncoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): SiLU()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): MarianDecoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianDecoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (activation_fn): SiLU()\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",")\n"]}],"source":["# [Test] tokenizer, model\n","print(tokenizer, model)"]},{"cell_type":"markdown","metadata":{"id":"Z6mM0ZstH_R6"},"source":["## 5. 사용자 정의 Dataset 정의"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1722177284080,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"4iSfJP9w7jYg"},"outputs":[],"source":["class CustomDataset(Dataset):\n","\n","    \"\"\" 데이터를 토큰화 및 텐서로 변환하는 Dataset을 재정의한 클래스 \"\"\"\n","\n","    def __init__(self, max_length=128):\n","        self.max_length = max_length\n","        self.model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","        self.tokenizer = MarianTokenizer.from_pretrained(self.model_name)\n","\n","    # tokenizer 정의\n","    def tokenizer_function(self, data):\n","        return self.tokenizer(\n","            data,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True\n","        )\n","\n","    # 학습을 위한 Dataset\n","    def get_inputs(self, df):\n","        input_pairs = []  # 모델에 학습시킬 데이터(텐서)를 저장할 리스트\n","\n","        for i in range(len(df)):\n","            # input 및 target 데이터 추출\n","            input_text = df.iloc[i, 0]\n","            target_text = df.iloc[i, 1]\n","\n","            # input 및 target 데이터 토큰화\n","            input_ids = self.tokenizer_function(input_text)\n","            target_ids = self.tokenizer_function(target_text)\n","\n","            # 모델에 학습시킬 데이터 -> 텐서로 변환\n","            input_pair = {'input_ids' : torch.LongTensor(input_ids['input_ids']),\n","                          'attention_mask' : torch.LongTensor(input_ids['attention_mask']),\n","                          'labels' : torch.LongTensor(target_ids['input_ids'])}\n","\n","            input_pairs.append(input_pair)\n","\n","        return input_pairs\n","\n","    # 생성 및 성능측정의 위한 Dataset\n","    def get_input_ids(self, df):\n","        input_ids_list = []  # 모델에 생성 및 성능측정할 데이터(텐서)를 저장할 리스트\n","\n","        for i in range(len(df)):\n","            # input 데이터 추출\n","            input_text = df.iloc[i, 0]\n","\n","            # input 데이터 토큰화\n","            input_ids = self.tokenizer(input_text, padding=\"max_length\", max_length=self.max_length, truncation=True)[\"input_ids\"]\n","            input_ids_list.append(input_ids)\n","\n","        return torch.tensor(input_ids_list)  # 텐서 변환"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":723,"status":"ok","timestamp":1722177284779,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"o7Nd9BlfVytf"},"outputs":[],"source":["# Dataset 정의\n","custom_dataset = CustomDataset()\n","\n","# Dataset 생성\n","dataset_train = custom_dataset.get_inputs(train_df)\n","dataset_val = custom_dataset.get_inputs(valid_df)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1722177284779,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"6THiYe0rQSUf","outputId":"debbb6c9-eaa9-447f-d818-c9d9084c04a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset_train len : 350\n"]},{"data":{"text/plain":["{'input_ids': tensor([ 2157,   131,   157,  9986, 16879,   131, 28690,    48, 13572,   253,\n","             9, 15009, 21955, 15604, 16491, 35778, 16149,   163,  7356,  4827,\n","          1085,  5468,   640,    40,  1787,   450,  2771,  1492,  1282,   989,\n","          4646, 34975, 29847,    62,   362, 22946,  1881,   168, 25604,  9870,\n","          1698,  1327,   450,  2771,   162,   541,  2469, 40264,   450,  2771,\n","           234, 36844,   161,     2,     0, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([   57,     9, 11927, 23269,  8473,  1921,     6,  1640,  1438,  7932,\n","          2936,     6,     4,     9, 15077,   649,   897,  7460,   639,     6,\n","             9,  5732,  9561,  1641,  5708,     9,  3520, 16807,    61,    31,\n","             9,  3780,  9432,  2936,   194,    13,    73,  1731,   494,  1132,\n","          3569,   639,     9,  4504, 40977,    10,    26,  1681,  1013,    49,\n","           992,    10,    81,    38,     9,  2188,  1602,     5,  1835,  7932,\n","             9,  7490,     4,  2959,  1681,  1013, 31435,     9, 14434,  3128,\n","             4,  2959,    13,   897, 10488,  1681,   897,   101, 17871,    10,\n","          4225, 11341,     5,   430,  1028,  2730, 10368,   123,  9986,  4225,\n","          2135,  3778,     3,     8,    39,   295,  1487,  7405,  1439,     9,\n","          3520, 16807,     8,  1731,   494,  1132,  3569,   639,     9,  3520,\n","         16807,    26,     4,     9, 11372,   130,     9, 10262,  8283,    38,\n","          1487,  8513,   194,     2,     0, 65000, 65000, 65000])}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] Dataset\n","print(f'dataset_train len : {len(dataset_train)}')\n","dataset_train[0]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1722177284780,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"KlR2xYKTQWxW","outputId":"40f7be6e-24d5-493f-aff4-4b626d48345b"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset_val len : 35\n"]},{"data":{"text/plain":["{'input_ids': tensor([15823, 23428,  7092,  4078,  1034,  4399, 23988, 13652,  1034,     9,\n","         39728,   518,    51,  2341,  1034,   539,    85,  1052,  9194,  7533,\n","           249,   977,   349,   887, 14582,    48,  7297,  1011, 10434,  1046,\n","         23428,    79, 14552,   255,  3975,  5547,  3280,   578,  9355,   151,\n","           161,     2,     0, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([   57,  1495,  8910,     9,  7942, 38564,    20,    15,     4,  2441,\n","          8513,   649,  2936,  3963,  2025,     9,  1132,  2894,  2188,   897,\n","           194,  4874,  9719,  1850,  1053,  2253,  2652,     9,  2135,  6296,\n","          2936,    10,     5,     4,     9,  6009,   992,  9369,   123,   101,\n","          3843,  4268,  1487,  2895,  7613,   639,  8460,  2196,     8,  1495,\n","          2253, 44131,   639,     8, 18923, 28907,    59,   639,   595,  8460,\n","          2196,    10,     3,  1835, 11755,   130,     4,     9,  6229,    26,\n","             9,  6009,   992,  9369,     5,    31,    73,  5259,   194,     9,\n","          2188,  4732,  5566,  9369,  5838,     9,  4257,  1640,  5613,    10,\n","          4268,    68,     4,  1731,  2959,  9631,   977,  4545, 43206,    10,\n","             6,  1835,   101,  1673,   649,  1132, 15489,     2,     0, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n","         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000])}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# [Test] Dataset\n","print(f'dataset_val len : {len(dataset_val)}')\n","dataset_val[0]"]},{"cell_type":"markdown","metadata":{"id":"WuvpzS9XR2rD"},"source":["## 6. 사용자 정의 CustomModel 재정의"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177284780,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"zf5e4DQIR15Z"},"outputs":[],"source":["class CustomModel(nn.Module):\n","\n","    \"\"\" fine-tuning하기 위해 pretrained 모델인 MarianMT 모델 재정의한 클래스 \"\"\"\n","\n","    def __init__(self, custom_dataset, model_name, decoder_layers=6, dropout=None):\n","        super().__init__()\n","        config = MarianConfig.from_pretrained(model_name)  # 모델 구성요소\n","        config.decoder_layers = decoder_layers  # 디코더\n","        self.custom_dataset = custom_dataset  # 데이터셋\n","        self.model = MarianMTModel.from_pretrained(model_name, config = config)  # 모델 정의\n","\n","        # dropout\n","        if dropout:\n","            self.model.dropout = dropout\n","\n","        # encoder freezing\n","        for param in self.model.get_encoder().parameters():\n","            param.requires_grad = False\n","\n","        self.batch_size = -1\n","        self.batch_cnt = -1\n","\n","    # 모델 학습\n","    def train(self, training_args, train_df, valid_df):\n","        # train / validation Dataset 로드\n","        train_dataset = self.custom_dataset.get_inputs(train_df)\n","        valid_dataset = self.custom_dataset.get_inputs(valid_df)\n","\n","        # 학습\n","        trainer = Trainer(\n","            model=self.model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=valid_dataset,\n","        )\n","\n","        trainer.train()\n","\n","    # 모델 생성\n","    def generate(self, df):\n","        # 생성 및 성능측정의 위한 Dataset 로드\n","        input_ids = self.custom_dataset.get_input_ids(df)\n","\n","        # 문장 생성\n","        outputs = self.model.generate(input_ids.to(device), max_length=128)\n","\n","        # 문장으로 변환\n","        output_sentences = []\n","        for output in outputs:\n","            output_sentences.append(tokenizer.decode(output, skip_special_tokens=True))\n","\n","        return output_sentences\n","\n","    # batch 단위 정확도 측정(BLEU)\n","    def batch_accuracy(self, df):\n","        self.batch_cnt += 1\n","\n","        # 모델 생성 결과\n","        output_sentences = self.generate(df)\n","\n","        # target(번역문)\n","        target_sentences = [sentence for sentence in df['번역문']]\n","\n","        # 현재 배치 문장 개수, 정확도\n","        batch_sen_cnt, accuracy_cnt =  0, 0\n","\n","        \"\"\"\n","        BLEU: output 단어가 target에 포함된 정도\n","        ROUGE: target 단어가 output에 포함된 정도\n","        \"\"\"\n","\n","        # SmoothingFunction 정의\n","        # smoothing_function = SmoothingFunction().method1  # method1: 기본적인 smoothing 방법\n","\n","        print(f'### {self.batch_cnt} batch start ###')\n","        for i in range(len(df)):\n","            batch_sen_cnt += 1\n","\n","            output_sentence = output_sentences[i]  # 모델 생성 결과(번역문)\n","            target_sentence = target_sentences[i]  # target(번역문)\n","\n","            # 문장을 토큰 단위로 나누기\n","            candidate = output_sentence.split()   # 생성된 문장을 토큰 단위로 나누기\n","            reference = [target_sentence.split()]   # 참조 문장(target)을 토큰 단위로 나누기\n","\n","            # 1-gram, 2-gram, 3-gram, 4-gram 평가\n","            weights = (1.0, 1.0, 1.0, 1.0)\n","\n","            # BLEU 점수 계산\n","            bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","            accuracy_cnt += bleu_score\n","\n","        # 배치 단위 평균 BLEU 점수 측정\n","        performance = accuracy_cnt / batch_sen_cnt\n","        print(f'{self.batch_cnt} batch BLEU performance : {performance}\\n')\n","\n","        return performance\n","\n","    # # batch 단위 정확도 측정(똑같으면 1, 하나라도 다르면 0)\n","    # def batch_accuracy(self, df):\n","    #     self.batch_cnt += 1\n","\n","    #     # 모델 생성 결과\n","    #     output_sentences = self.generate(df)\n","\n","    #     # target(번역문)\n","    #     target_sentences = [sentence for sentence in df['번역문']]\n","\n","    #     # 현재 배치 문장 개수, 정확도\n","    #     batch_sen_cnt, accuracy_cnt = 0, 0\n","\n","    #     print(f'### {self.batch_cnt} batch start ###')\n","    #     for i in range(len(df)) :\n","    #         batch_sen_cnt += 1\n","\n","    #         output_sentence = output_sentences[i]  # input으로 모델 생성 결과(번역문)\n","    #         target_sentence = target_sentences[i]  # target(번역문)\n","\n","    #         # 정확도 카운트\n","    #         if output_sentence == target_sentence :\n","    #             accuracy_cnt += 1\n","    #         else :\n","    #             self.test_result[0].append(output_sentence)\n","    #             self.test_result[1].append(target_sentence)\n","\n","    #     # batch 단위 정확도 측정\n","    #     performance = accuracy_cnt / batch_sen_cnt\n","    #     print(f'{self.batch_cnt} batch performance : {performance}\\n')\n","\n","    #     return performance\n","\n","    # 총 정확도 측정\n","    def total_test_accuracy(self, df, batch_size):\n","        self.batch_size = batch_size\n","        self.batch_cnt = 0\n","        self.test_result = [[], []]\n","\n","        start, end = 0, self.batch_size\n","\n","        performance = 0\n","        while 1:\n","            if start >= len(df):\n","                break\n","\n","            end = min(end, len(df))\n","\n","            # 현재 배치에 대한 정확도를 측정하여 누적\n","            performance += self.batch_accuracy(df[start:end])\n","\n","            start = end  # 시작 인덱스를 끝 인덱스로 업데이트\n","            end += self.batch_size  # 끝 인덱스를 배치 크기만큼 증가\n","\n","        # 총 정확도 측정\n","        performance /= self.batch_cnt\n","        print(f'final performance : {performance}')\n","\n","        return performance\n","\n","    def return_model(self):\n","        return self.model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1722177284781,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"RQ3myBbvhnsa"},"outputs":[],"source":["# 아래 실행하지 마시오!"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1722177284782,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"SVj_mUvJhkfO"},"outputs":[],"source":["# 아래 실행하지 마시오!"]},{"cell_type":"markdown","metadata":{"id":"Lq2BSZAq1xvI"},"source":["## 7. Fine-tuning"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1018214,"status":"ok","timestamp":1722178306861,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"DfGagPn9YY6R","outputId":"c1fc055d-8158-4e13-a04b-d92e5ea365e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:49, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 8.036855140815083e-05\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.000595318985056105\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 2.3651994461892806e-05\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.0002466941701014961\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.00014049407095816048\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 8.87666385669557e-05\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 6.929132510894393e-05\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 9.41364080175138e-06\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.0006024112688210565\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 4.070813455066736e-05\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.00038250431561550724\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.00017490378757383128\n","\n","final performance : 0.0002045439069187099\n","25 epoch performance : 0.0002045439069187099\n","25 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.0008946055189552148\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.0023058814138638556\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.0005853981308964397\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.003668207537738592\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.003983396001330227\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.0008711839345660415\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.0006682297085401975\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.0005604014107392209\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.0009818515620717938\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.0009314942384123361\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.00254358161329247\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.0015924269468752944\n","\n","final performance : 0.0016322215014401402\n","50 epoch performance : 0.0016322215014401402\n","50 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.015141958461599768\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.03720690614776855\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.011865745737870043\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.011329824344093232\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.010030178658256849\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.022536141693621035\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.01160570110766767\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.0034593782379337638\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.008873064074389536\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.040974573005548756\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.02273022694709739\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.016339233735183666\n","\n","final performance : 0.017674411012585853\n","75 epoch performance : 0.017674411012585853\n","75 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.09411389259516051\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.10775029225726486\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.035993365469332586\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.09005791659777525\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.08416035299087475\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.08915232754327258\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.0966790570631373\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.06328220665089607\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.07044720244527193\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.1047130584074243\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.08143235528234564\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.13219412662156219\n","\n","final performance : 0.0874980128270265\n","100 epoch performance : 0.0874980128270265\n","100 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.3138237790408136\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 2 batch start ###\n","2 batch BLEU performance : 0.34447822979165404\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.27228902760698415\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.3561611327771157\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.2663455068668228\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.39099665997370386\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 7 batch start ###\n","7 batch BLEU performance : 0.26611211885231045\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.3144602506510052\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.36958401827940546\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.4180165139994948\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.3488656681475798\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.34488548093361565\n","\n","final performance : 0.3338348655767088\n","125 epoch performance : 0.3338348655767088\n","125 epoch is best model\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:32, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.5507375304135199\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.5990324110180109\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.6004235580545644\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["### 4 batch start ###\n","4 batch BLEU performance : 0.664938810723498\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.5273016055985253\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.6285646870836775\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.5310965100680582\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.545942180242578\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.6115025072988425\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.5026320594648634\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.5351338136626356\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.6198105650753712\n","\n","final performance : 0.5764263532253454\n","150 epoch performance : 0.5764263532253454\n","150 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:32, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.706641214039298\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7470705973411427\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.7589007670459795\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.6911384773328094\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.7088729450207469\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.7350406930474875\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7309799958459776\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.7485273471678713\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.750105520787913\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.7198793854888217\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.71520738401241\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.6969151237693638\n","\n","final performance : 0.7257732875749853\n","175 epoch performance : 0.7257732875749853\n","175 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.7558844030013456\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7415264984522533\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8186531000067466\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7690759016146937\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.7989855341343919\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8376069290906704\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7707757732777025\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8013166023527436\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.8049200970604161\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.7820778840569884\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8471424616277683\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8213843122386562\n","\n","final performance : 0.7957791247428648\n","200 epoch performance : 0.7957791247428648\n","200 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8046137114103246\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.7989026013434323\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8458304660147332\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7803041439456282\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8343776437286646\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8332298380654677\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7154576956497717\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8474668347795755\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.7673694485455979\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.867838681399079\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8800521691738382\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.7928653204768007\n","\n","final performance : 0.8140257128777427\n","225 epoch performance : 0.8140257128777427\n","225 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8567583151054091\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.794135185025688\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8688711417036129\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.7903144743674682\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8175429259629624\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8654909120550013\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.7830192016651313\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8048734740129435\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.831490201177055\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.8622038556567969\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.9516491642978254\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8465158948141486\n","\n","final performance : 0.8394053954870034\n","250 epoch performance : 0.8394053954870034\n","250 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:33, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8412922397602127\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.8215852782487131\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8698891285576218\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.8534746160550709\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.8818268394585661\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8263698991113946\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.85138432513369\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.8274206289150402\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.8993763205339872\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.9106843749419293\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8468431028899247\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8515713286891146\n","\n","final performance : 0.8568098401912722\n","275 epoch performance : 0.8568098401912722\n","275 epoch is best model\n","\n","Best model saved.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 00:34, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"]},{"name":"stdout","output_type":"stream","text":["### 1 batch start ###\n","1 batch BLEU performance : 0.8857185225613569\n","\n","### 2 batch start ###\n","2 batch BLEU performance : 0.8242985020564572\n","\n","### 3 batch start ###\n","3 batch BLEU performance : 0.8428079739175018\n","\n","### 4 batch start ###\n","4 batch BLEU performance : 0.8134973015851529\n","\n","### 5 batch start ###\n","5 batch BLEU performance : 0.768028152492548\n","\n","### 6 batch start ###\n","6 batch BLEU performance : 0.8523013393814376\n","\n","### 7 batch start ###\n","7 batch BLEU performance : 0.8407412629905997\n","\n","### 8 batch start ###\n","8 batch BLEU performance : 0.7958590694146356\n","\n","### 9 batch start ###\n","9 batch BLEU performance : 0.9031515257907201\n","\n","### 10 batch start ###\n","10 batch BLEU performance : 0.9171484968532532\n","\n","### 11 batch start ###\n","11 batch BLEU performance : 0.8458522511931073\n","\n","### 12 batch start ###\n","12 batch BLEU performance : 0.8077880616398394\n","\n","final performance : 0.8414327049897175\n","300 epoch performance : 0.8414327049897175\n","Tunning Success.\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 모델 정의 및 초기화\n","model = CustomModel(custom_dataset, model_name)\n","model.return_model()\n","\n","# 모델 저장 경로 설정\n","model_path = \"/content/drive/MyDrive/model/\"\n","\n","# 학습 Epoch, Batch, Step 정의\n","num_train_epochs = 25\n","batch_size = 30\n","step = 500\n","\n","# 학습 변수\n","training_args = TrainingArguments(\n","    output_dir=model_path,\n","    overwrite_output_dir=True,\n","    num_train_epochs=num_train_epochs,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    eval_steps=step,\n","    save_steps=step,\n","    logging_steps=step,\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","# 모델 학습(600 epoch)\n","performance_max = 0\n","try:\n","    for i in range(24):  # 25 * 24 = 600 epoch\n","        model.train(training_args, train_df, valid_df)\n","        performance = model.total_test_accuracy(train_df, batch_size=batch_size)  # 성능측정\n","        print(f'{num_train_epochs * (i+1)} epoch performance : {performance}')\n","\n","        if performance_max < performance:  # 현재 성능이 이전 최고 성능보다 좋으면 모델 저장\n","            performance_max = performance\n","            print(f'{num_train_epochs * (i+1)} epoch is best model\\n')\n","            # torch.save(model,\"/content/drive/MyDrive/model/marian_fine_tunned_model_v1_3.pt\")\n","            torch.save(model.return_model().state_dict(), \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\")\n","            print(\"Best model saved.\")\n","        else:\n","            # 현재 성능이 이전 최고 성능보다 좋지 않으면 이전 모델로 저장하고 학습 중단\n","            print(\"Tunning Success.\")\n","            break\n","\n","except KeyboardInterrupt:\n","    if performance_max > 0:  # 이전 성능이 있을 경우에만 저장\n","        # torch.save(model, \"/content/drive/MyDrive/model/marian_fine_tunned_model_v1_3.pt\")\n","        torch.save(model.return_model().state_dict(), \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\")\n","        print(\"Best model saved.\")"]},{"cell_type":"markdown","metadata":{"id":"6Gn7wnaXWJPa"},"source":["## 8. Fine-tunning 결과 확인(Train Dataset)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14877,"status":"ok","timestamp":1722179347736,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"L92H75Sc9rnU","outputId":"9c02f1b6-662f-4f19-fa71-8d30b12b7d28"},"outputs":[{"name":"stdout","output_type":"stream","text":["generated_text: The suspension of repayment of the principal of household loans will be implemented in all financial sectors for debtors who are unable to pay off their debts after their income decreases due to COVID-19 damage, and only credit loans and financial loans for the working class are covered.\n","target_text: The suspension of repayment of the principal of household loans will be implemented in all financial sectors for debtors who are unable to pay off their debts after their income decreases due to COVID-19 damage, and only credit loans and financial loans for the working class are covered.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Vice President Lee of Kakao Pay held a press conference and said his future business goal is a paperless society, which aims to expand services that can receive various bills through Kakao Talk platforms.\n","target_text: Vice President Lee of Kakao Pay held a press conference and said his future business goal is a paperless society, which aims to expand services that can receive various bills through Kakao Talk platforms.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Counterpoint Research analyzed that Xiaomi is expanding its influence in China's home turf and global markets under the influence of Flower's sanctions in Europe and Latin America.\n","target_text: Counterpoint Research analyzed that Xiaomi is expanding its influence in China's home turf and global markets under the influence of Flower's sanctions in Europe and Latin America.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Super chaebol institutional investors such as BlackRock and Vanguard should be allowed to operate according to the standards of the corporation system principle, not moral standards.\n","target_text: Super chaebol institutional investors such as BlackRock and Vanguard should be allowed to operate according to the standards of the corporation system principle, not moral standards.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Naver will launch a subscription service that allows users to use Naver's major services if they pay a monthly subscription fee.\n","target_text: Naver will launch a subscription service that allows users to use Naver's major services if they pay a monthly subscription fee.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: The death toll in Daegu increased to 54 as the man, who had an underlying disease, died at Kyungpook National University Hospital due to cardiac arrest.\n","target_text: The death toll in Daegu increased to 54 as the man, who had an underlying disease, died at Kyungpook National University Hospital due to cardiac arrest.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Among those from the Blue House who were candidates for the 21st general election, 64% of the total were certain, confirmed, and likely candidates, but some were in a close race.\n","target_text: Among those from the Blue House who were candidates for the 21st general election, 64% of the total were certain, confirmed, and likely candidates, but some were in a close race.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Concerned about COVID-19, the Incheon Metropolitan Government decided to establish an online grave and memorial service at Incheon Family Park, the largest commercial facility in Incheon.\n","target_text: Concerned about COVID-19, the Incheon Metropolitan Government decided to establish an online grave and memorial service at Incheon Family Park, the largest commercial facility in Incheon.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Aerobic exercises such as jogging, walking, swimming, cycling, and light hiking can lower triglycerides and cholesterol levels that cause arteriosclerosis for arterial health care.\n","target_text: Aerobic exercises such as jogging, walking, swimming, cycling, and light hiking can lower triglycerides and cholesterol levels that cause arteriosclerosis for arterial health care.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Cheong Wa Dae has decided to accept all suggestions from the business community presented at the meeting of the business community in response to COVID-19 and promptly implement follow-up measures.\n","target_text: Cheong Wa Dae has decided to accept all suggestions from the business community presented at the meeting of the business community in response to COVID-19 and promptly implement follow-up measures.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: In addition, the Democratic Party of Korea chose for citizens as a proportional coalition platform, laying the groundwork for a proportional coalition party, and the basic income party and the transition of the times joined, excluding the political reform coalition.\n","target_text: In addition, the Democratic Party of Korea chose for citizens as a proportional coalition platform, laying the groundwork for a proportional coalition party, and the basic income party and the transition of the times joined, excluding the political reform coalition.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: Director Park challenged the movie \"Hill of the Wind\" to a wandering screening that visited audiences all over the country.\n","target_text: Director Park challenged the movie \"Hill of the Wind\" to a wandering screening that visited audiences all over the country.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: At the emergency economic meeting, President Moon announced that he would implement emergency financial measures worth 50 trillion won as a package program for people's livelihoods and financial stability.\n","target_text: At the emergency economic meeting, President Moon announced that he would implement emergency financial measures worth 50 trillion won as a package program for people's livelihoods and financial stability.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: If the ventilation in the house is poor, the smell of ammonia and acetic acid in the bowel movement stresses cats, and it is the air purifier that is considered a solution to this.\n","target_text: If the ventilation in the house is poor, the smell of ammonia and acetic acid in the bowel movement stresses cats, and it is the air purifier that is considered a solution to this.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","generated_text: The competition held amid the COVID-19 incident was unfamiliar to Bae as he played without a gallery.\n","target_text: The competition held amid the COVID-19 incident was unfamiliar to Bae as he played without a gallery.\n","Match: True\n","\n","BLEU Score: 1.0\n","\n","--------------------------------------------------\n","==================================================\n","Average BLEU Score: 1.0\n"]}],"source":["# [Test] Fine-tunning 모델로 생성 및 타켓 평가(train dataset)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 데이터 불러오기\n","data_path = '/content/drive/MyDrive/'\n","train_df = pd.read_excel(data_path+'sum_tran_train.xlsx')[:15]\n","\n","# 모델과 토크나이저 불러오기\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","model = MarianMTModel.from_pretrained(model_name)\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# 저장된 모델(state dict) 불러오기\n","model_path = \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\"\n","model.load_state_dict(torch.load(model_path))\n","\n","# 모델을 평가 모드로 전환\n","model.to(device)\n","model.eval()\n","\n","bleu_scores = []\n","for i in range(len(train_df)):\n","    inputs = tokenizer(train_df.iloc[i, 0], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    attention_mask = inputs[\"attention_mask\"].to(device)\n","\n","    # 생성 및 변환\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # target\n","    target_text = train_df.iloc[i, 1]\n","\n","    print(f\"generated_text: {generated_text}\")\n","    print(f\"target_text: {target_text}\")\n","    print(f\"Match: {generated_text == target_text}\\n\")\n","\n","    # 1-gram, 2-gram, 3-gram, 4-gram 평가를 위한 가중치\n","    weights = (0.25, 0.25, 0.25, 0.25)\n","\n","    # BLEU 점수 계산\n","    candidate = generated_text.split()\n","    reference = [target_text.split()]\n","    bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","    bleu_scores.append(bleu_score)\n","    print(f\"BLEU Score: {bleu_score}\\n\")\n","    print(\"--------------------------------------------------\")\n","\n","avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(\"==================================================\")\n","print(f\"Average BLEU Score: {avg_bleu_score}\")"]},{"cell_type":"markdown","metadata":{"id":"Ml-yhf9vxui8"},"source":["## 9. Fine-tunning 결과 확인(Validation Dataset)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16420,"status":"ok","timestamp":1722179374614,"user":{"displayName":"David Choi","userId":"14870253108450991755"},"user_tz":-540},"id":"XnsR1LY4czeb","outputId":"85836df9-82f1-46b4-cbfb-a2084d7fa44f"},"outputs":[{"name":"stdout","output_type":"stream","text":["generated_text: It is oil to covernment the government's plan to enter the presidential and oppositional leader's party and lead measures to service events at the early 14 weeks of accountry.\n","target_text: The main point is that the government has announced legislative amendments to the abortion-related criminal law and maternal and child health laws, paving the way for abortion to be allowed unconditionally if requested by the first 14 weeks of pregnancy.\n","Match: False\n","\n","BLEU Score: 1.4875769488812793e-78\n","\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["generated_text: The Japan Mindropolitan Government revealed IAEA's announced crisis that is dayly imported in the worlds, causing disruptional prevention and expanding unique through on confirmed expression of political supply.\n","target_text: The Japanese government drew the IAEA's interpretation that marine discharge is routinely carried out around the world, insisting on the legitimacy of the discharge and highlighting transparent efforts to disclose information on the discharge of contaminated water.\n","Match: False\n","\n","BLEU Score: 9.65821029960698e-232\n","\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["generated_text: The hidden Choi Motors' Office is increasing, and the number of HUV is not in an official.\n","target_text: With the growing popularity of SUVs, Hyundai Motor's Sonata, which was called the national car, is not as popular as before.\n","Match: False\n","\n","BLEU Score: 4.1054243192424385e-155\n","\n","--------------------------------------------------\n","generated_text: Due to the time of debtinishment, Daek, which conducted his experience, which has been a diplobal instead of the company man, which has been a Daeju Church-kyeong team, and the  tastropany of Lee Jung-kyeung, a movicial company team that the administ\n","target_text: In fact, Hong, who worked as an in-house TOEIC instructor for a company during the globalization of the 90s, wrote the first draft, and director Lee's English TOEIC class, which was mixed with fictional settings, was released.\n","Match: False\n","\n","BLEU Score: 3.9421554930094576e-155\n","\n","--------------------------------------------------\n","generated_text: In the absence of the National Assembly and the National Assembly, Gang said, \"We are expected to have a contract spready that can receive the return of company while whiles.\"\n","target_text: Regarding the sexual harassment of embassies in New Zealand and Nigeria, Kang said, \"While I feel the limitations of leadership, it is the result of the Ministry of Foreign Affairs having a system that allows me to report freely report.\"\n","Match: False\n","\n","BLEU Score: 3.5840639204446147e-155\n","\n","--------------------------------------------------\n","generated_text: COVID-19 spreads against the number of confirmed with the sales of people and of expectary union, which has been more family enough an day.\n","target_text: The Chuseok holiday was more depressing than any other year due to the spread of COVID-19, which is directly related to the safety and respect for life of the people, and the murder of public officials.\n","Match: False\n","\n","BLEU Score: 8.396161215621529e-232\n","\n","--------------------------------------------------\n","generated_text: The betweening between City Commission was unable to know what was acquired in the longdang Dedong Park that was reignited by the confirming of the ASF virtually, which has been due to the concern of the National AssF visitive Party, which has been recorded exercessive.\n","target_text: The resumption of tourism, which was suspended due to the continued detection of the ASF virus in wild boars around the civilian control line, was unknown, and the co-chairman of the Yeoncheon Imjin River Citizens' Network was sorry.\n","Match: False\n","\n","BLEU Score: 2.5429199679442697e-78\n","\n","--------------------------------------------------\n","generated_text: As the nationwide of confirmation has been played by the China's representative national community and the National Committee, where the winding pandar is occurring due to the situation of COVID-19.\n","target_text: Holding the National People's Congress and the National Political Consultative Conference, which were postponed by China, the world is groaning over the COVID-19 incident, raising a fanfare of victory.\n","Match: False\n","\n","BLEU Score: 2.013654296748599e-78\n","\n","--------------------------------------------------\n","generated_text: Experts established that the streets of COVID-19 in Korea has increased the influence of cultural disasters, culture culture, and systems.\n","target_text: Experts predicted that the low number of COVID-19 confirmed cases in India is affected by the hot and humid climate, vegetarian food culture, and spices.\n","Match: False\n","\n","BLEU Score: 5.997822887308343e-155\n","\n","--------------------------------------------------\n","generated_text: Cleading the Seoul District Court, Lee has been received at the Korean Ministry and the Moinistry of Gyeonggi Province and the Ministry of Gyeon-gu, and it was revealed at an official state book, first increasing the artifiortain.\n","target_text: Laundry, set in Daldongne, Seoul, won awards at the Korean Musical Grand Prize and The Musical Awards, and the script was published for the first time in middle and high school textbooks.\n","Match: False\n","\n","BLEU Score: 1.945240729393877e-78\n","\n","--------------------------------------------------\n","generated_text: The sorry leaded an experience caller's representence to the ballening at Hotae Motors' when 17 players established their special instead for 100 days.\n","target_text: Soso Stationery displayed notes of 17 people writing down their interests for 100 days throughout Standard A's showroom so that visitors could see them.\n","Match: False\n","\n","BLEU Score: 4.258603586864609e-155\n","\n","--------------------------------------------------\n","generated_text: Handtohomide, which had a taxi transporter to the house's houseion, was emerging between the ruling companies after regional, but the bentz management has said heavy.\n","target_text: The home-to-home service, which picks up the car to the customer's house and returns it after repair, was higher in unit price than the general maintenance plant, but a large number of Mercedes-Benz vehicle owners flocked.\n","Match: False\n","\n","BLEU Score: 3.3620599903439287e-155\n","\n","--------------------------------------------------\n","generated_text: It is possibility that China's exercise of strengthing of COVID-19 will be implemented in Seoul and play into Chinaul, which will introduc a strengthly suspictment scenarming around to change the spread of COVID-19.\n","target_text: Chinese authorities are expected to implement strong measures in Heilongjiang Province, including the death penalty for those who deliberately spread the coronavirus epidemic, and expand them across China.\n","Match: False\n","\n","BLEU Score: 1.136638440788832e-231\n","\n","--------------------------------------------------\n","generated_text: In a survey play local players in Cheon's announcement, confirmations caused due to the resulting party's country, controversy are raising confirmed against its effect.\n","target_text: The theory of uselessness of local currency contained in the report released by Cho Se-yeon is intensifying controversy over the effectiveness of local currency, starting with criticism from the governor of Gyeonggi Province.\n","Match: False\n","\n","BLEU Score: 8.00037014003153e-232\n","\n","--------------------------------------------------\n","generated_text: Due to concernal continuation, domestic markets are treated as screenctions and drugs, which is argantly arounding polices all over the country, but they do not expect to be removed.\n","target_text: Wild animals are being used for decoration or medicine through illegal capture, so poaching is strongly regulated around the world, but it does not seem to be eradicated.\n","Match: False\n","\n","BLEU Score: 4.545249402532287e-155\n","\n","--------------------------------------------------\n","==================================================\n","Average BLEU Score: 5.326261295312016e-79\n"]}],"source":["# [Test] Fine-tunning 모델로 생성 및 타켓 평가(valid dataset)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 데이터 불러오기\n","data_path = '/content/drive/MyDrive/'\n","valid_df = pd.read_excel(data_path+'sum_tran_valid.xlsx')[:15]\n","\n","# 모델과 토크나이저 불러오기\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","model = MarianMTModel.from_pretrained(model_name)\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","# 저장된 모델(state dict) 불러오기\n","model_path = \"/content/drive/MyDrive/model/marian_fine_tunned_model_state_dict_v1_3.pt\"\n","model.load_state_dict(torch.load(model_path))\n","\n","# 모델을 평가 모드로 전환\n","model.to(device)\n","model.eval()\n","\n","bleu_scores = []\n","for i in range(len(valid_df)):\n","    inputs = tokenizer(valid_df.iloc[i, 0], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    attention_mask = inputs[\"attention_mask\"].to(device)\n","\n","    # 생성 및 변환\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # target\n","    target_text = valid_df.iloc[i, 1]\n","\n","    print(f\"generated_text: {generated_text}\")\n","    print(f\"target_text: {target_text}\")\n","    print(f\"Match: {generated_text == target_text}\\n\")\n","\n","    # 1-gram, 2-gram, 3-gram, 4-gram 평가를 위한 가중치\n","    weights = (0.25, 0.25, 0.25, 0.25)\n","\n","    # BLEU 점수 계산\n","    candidate = generated_text.split()\n","    reference = [target_text.split()]\n","    bleu_score = sentence_bleu(reference, candidate, weights=weights)\n","    bleu_scores.append(bleu_score)\n","    print(f\"BLEU Score: {bleu_score}\\n\")\n","    print(\"--------------------------------------------------\")\n","\n","avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(\"==================================================\")\n","print(f\"Average BLEU Score: {avg_bleu_score}\")"]},{"cell_type":"markdown","metadata":{"id":"2iyMkN7t5AVW"},"source":["#### 내용 요약 & 결론: 지난 프로젝트 모델 튜닝에 BLEU 성능측정을 추가하여 복습하고자 했다. 그래서 시간 단축 및 컴퓨팅 자원 절약을 위해 적은 양의 train 데이터로 모델을 튜닝했다. 하지만 결과는 모델이 train 데이터에만 과적합되었다. 따라서 튜닝된 모델은 학습한 train 데이터의 패턴이 valid 데이터를 충분히 반영하지 못했고 이를 해결하기 위해서는 더 많은 데이터로 패턴을 학습시켜함을 느꼈다."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01f9b1bbab5940e89f4ede691f449186":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48cb922e710416aaa9cb98320114660","placeholder":"​","style":"IPY_MODEL_842391b85c1344bb9d5c01f87db6af90","value":"tokenizer_config.json: 100%"}},"0200f3ffdb144b46ab22031e180d42c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_827721f0786e4a4eaeab5ab1350452c5","max":813126,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5fd3bce32644150b5edddfac644c4ca","value":813126}},"0563b2f5e5ee4d47bce6219d7403a22b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8846a7d62c4bfdaa586a9b3dd8f38e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efdac02a822460daf5f1fc79da062ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6011c3f1a2fc4193b25cf1402f1da524","IPY_MODEL_26180c7a68f3446b9cc2c0f5959b0cbe","IPY_MODEL_3ccda280f6564891a3168bed90d66965"],"layout":"IPY_MODEL_ad8fcdb8b5b342bab2841a5ed577987b"}},"12e0b17dd4eb47019ba73f8c822f2d72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"139be2cc5a4c41f6b59cad4b28396cb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"181193808d154ab6ab06139a1431a45d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_369b7f4ccb9645a5916ad175eeecca45","placeholder":"​","style":"IPY_MODEL_a8da0773f20543fe9db10b77a13b3cf7","value":"target.spm: 100%"}},"1a969522b87942689a54999b73282fea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24677bc16fb749a0ab04dd1c8cb1c0eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8846a7d62c4bfdaa586a9b3dd8f38e","max":312087009,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d756e78768d420ea1390d0b56ea14db","value":312087009}},"26180c7a68f3446b9cc2c0f5959b0cbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb8d0dffdfec4ed2bbe97c59708418b7","max":1394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58c3d62b797647af9ee1a353a18ffe7e","value":1394}},"2f4afbbce8f1493d9bad76ec095547e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e8f5a03dec64cf0b7b1f740fb4348be","IPY_MODEL_b43cc672daf14d888c88b77bea3f8491","IPY_MODEL_8f75a9e777f34f639968891bc6b29782"],"layout":"IPY_MODEL_6e04e4df1f8346b993ef3ea0fd5ba650"}},"3637fb87d5034918b35635ba21b94b72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"369b7f4ccb9645a5916ad175eeecca45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3793225c8851405ba0c5e316562edf7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ccda280f6564891a3168bed90d66965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3793225c8851405ba0c5e316562edf7b","placeholder":"​","style":"IPY_MODEL_4afeb784e45c489383c420242e6c6b81","value":" 1.39k/1.39k [00:00&lt;00:00, 107kB/s]"}},"45fcbdb03e2d41af8f71ddb313375d4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afeb784e45c489383c420242e6c6b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e594b68d5464ddd918f753bafe1ed96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8f5a03dec64cf0b7b1f740fb4348be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc08c6ebfa944e2aa53b82dc3068292","placeholder":"​","style":"IPY_MODEL_d4cddfedced5416f81e4cf4c57136035","value":"source.spm: 100%"}},"5110cd60952b40788becef79b0c96717":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514a9ed5e4834fe09f3019e98e970b09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c3d62b797647af9ee1a353a18ffe7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5af2c3aa4b564bdfb9fcdd6d554ec233":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc18f7dba0b749b6bc3c34724aa70a8c","IPY_MODEL_24677bc16fb749a0ab04dd1c8cb1c0eb","IPY_MODEL_e29b3eac44c745a195b9f7bea16e9944"],"layout":"IPY_MODEL_7dce201b10dd48ca94e992447150d535"}},"5b4dc50063b04d5a93227125982b2e94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d756e78768d420ea1390d0b56ea14db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6011c3f1a2fc4193b25cf1402f1da524":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_514a9ed5e4834fe09f3019e98e970b09","placeholder":"​","style":"IPY_MODEL_de3015d0242c43dba3f491b06510bebc","value":"config.json: 100%"}},"6343603066794320b2fbb17a1d19c64d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b26edd9dd91f405391f9989f4383b451","IPY_MODEL_c28b94deafe34d1389a10fe0dfeedd54","IPY_MODEL_cb1e0f6451e944029b250ec415e75a7b"],"layout":"IPY_MODEL_45fcbdb03e2d41af8f71ddb313375d4b"}},"6591aed40e7543b0820b0a6e7c8d2a2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_181193808d154ab6ab06139a1431a45d","IPY_MODEL_0200f3ffdb144b46ab22031e180d42c3","IPY_MODEL_727ba9717fc249648919f0f4a0f45260"],"layout":"IPY_MODEL_3637fb87d5034918b35635ba21b94b72"}},"6e04e4df1f8346b993ef3ea0fd5ba650":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727ba9717fc249648919f0f4a0f45260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5110cd60952b40788becef79b0c96717","placeholder":"​","style":"IPY_MODEL_d3d195e65ac3439aae7fb9b060b9f129","value":" 813k/813k [00:00&lt;00:00, 926kB/s]"}},"72e6f83dd4df475082135ba9befc977c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75604c9279ab4628bedbe0b10aa9c1be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1162b31f6c34cd1b7f139a4a462a45f","IPY_MODEL_f9139877639445b28a900f9e1de7eb29","IPY_MODEL_c45dac4045fc47b2a5d385b403551c85"],"layout":"IPY_MODEL_0563b2f5e5ee4d47bce6219d7403a22b"}},"7771afadf5c548bcacf3b7cdf04b2965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01f9b1bbab5940e89f4ede691f449186","IPY_MODEL_ab9f7fdcbdaa4e19b015afcb404e65ee","IPY_MODEL_f378be1fd1e94f7383802db7542f651d"],"layout":"IPY_MODEL_da15cd42ccdc445ab7bd616f5b485bbd"}},"7dce201b10dd48ca94e992447150d535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"827721f0786e4a4eaeab5ab1350452c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"842391b85c1344bb9d5c01f87db6af90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"893af6876a6544ed8710d2f578c4cd17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f75a9e777f34f639968891bc6b29782":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_962b13e90d164805ad4d2fda6f8518d7","placeholder":"​","style":"IPY_MODEL_b0d69b5925b248838591a13850419f00","value":" 842k/842k [00:00&lt;00:00, 962kB/s]"}},"962b13e90d164805ad4d2fda6f8518d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc08c6ebfa944e2aa53b82dc3068292":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6db92ad600c4ab6b5e22ac2b9d63aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8da0773f20543fe9db10b77a13b3cf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab9f7fdcbdaa4e19b015afcb404e65ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7db8133f5aa4afab4ac2e1926707f19","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6db92ad600c4ab6b5e22ac2b9d63aca","value":44}},"ad8fcdb8b5b342bab2841a5ed577987b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0d69b5925b248838591a13850419f00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b26edd9dd91f405391f9989f4383b451":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e594b68d5464ddd918f753bafe1ed96","placeholder":"​","style":"IPY_MODEL_72e6f83dd4df475082135ba9befc977c","value":"generation_config.json: 100%"}},"b2b4aa9fac06489bb1cdc4e8a272d260":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43cc672daf14d888c88b77bea3f8491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce5de4c3598448228f90e2cc60c68302","max":841805,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12e0b17dd4eb47019ba73f8c822f2d72","value":841805}},"bb8d0dffdfec4ed2bbe97c59708418b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc09af2b929340999a32301295a78348":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c28b94deafe34d1389a10fe0dfeedd54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15dffeb454c4dc9a766cb05aa074bd6","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_893af6876a6544ed8710d2f578c4cd17","value":293}},"c45dac4045fc47b2a5d385b403551c85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a969522b87942689a54999b73282fea","placeholder":"​","style":"IPY_MODEL_139be2cc5a4c41f6b59cad4b28396cb0","value":" 1.72M/1.72M [00:00&lt;00:00, 7.14MB/s]"}},"cb1e0f6451e944029b250ec415e75a7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede84c66848545378235d83b7d9e8faf","placeholder":"​","style":"IPY_MODEL_de72e131915544e9a728edaaa1ac68ef","value":" 293/293 [00:00&lt;00:00, 25.3kB/s]"}},"ce5de4c3598448228f90e2cc60c68302":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce6dfc1b1e484ff286dad5b5648ee7b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1162b31f6c34cd1b7f139a4a462a45f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce6dfc1b1e484ff286dad5b5648ee7b5","placeholder":"​","style":"IPY_MODEL_f85b18fef9c842c583c2c11688b4fed0","value":"vocab.json: 100%"}},"d3d195e65ac3439aae7fb9b060b9f129":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d48cb922e710416aaa9cb98320114660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4cddfedced5416f81e4cf4c57136035":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d59047c3687b4812b7891a9668cbed17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6253f9cfe68460cbcfec407997254e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7db8133f5aa4afab4ac2e1926707f19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8e453789e0848e3a684ed9dc4b73f5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da15cd42ccdc445ab7bd616f5b485bbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc18f7dba0b749b6bc3c34724aa70a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b4dc50063b04d5a93227125982b2e94","placeholder":"​","style":"IPY_MODEL_d59047c3687b4812b7891a9668cbed17","value":"pytorch_model.bin: 100%"}},"de3015d0242c43dba3f491b06510bebc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de72e131915544e9a728edaaa1ac68ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29b3eac44c745a195b9f7bea16e9944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6253f9cfe68460cbcfec407997254e0","placeholder":"​","style":"IPY_MODEL_f1a8f61b88d94d748dd39adb0cd060e3","value":" 312M/312M [00:01&lt;00:00, 236MB/s]"}},"e4fd9a73d3fb4621ac01bd640da8d9a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5fd3bce32644150b5edddfac644c4ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ede84c66848545378235d83b7d9e8faf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15dffeb454c4dc9a766cb05aa074bd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a8f61b88d94d748dd39adb0cd060e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f378be1fd1e94f7383802db7542f651d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2b4aa9fac06489bb1cdc4e8a272d260","placeholder":"​","style":"IPY_MODEL_d8e453789e0848e3a684ed9dc4b73f5d","value":" 44.0/44.0 [00:00&lt;00:00, 3.42kB/s]"}},"f85b18fef9c842c583c2c11688b4fed0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9139877639445b28a900f9e1de7eb29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc09af2b929340999a32301295a78348","max":1719866,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4fd9a73d3fb4621ac01bd640da8d9a4","value":1719866}}}}},"nbformat":4,"nbformat_minor":0}
